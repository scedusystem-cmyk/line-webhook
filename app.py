# app.py
# ============================================
# å°šé€²ã€Šå¯„æ›¸ï¼‹é€²éŠ·å­˜ è‡ªå‹•åŒ–æ©Ÿå™¨äººã€‹â€” 18é …æœ€çµ‚ç‰ˆ å¯¦ä½œ
# æ¶æ§‹ï¼šFlask + LINE Webhook + Google Sheets +ï¼ˆé¸ï¼‰Vision OCR
# é—œéµï¼šå»ºæª”ã€Œä¸Šæ–°ä¸‹èˆŠã€ï¼ˆæ’å…¥ç¬¬2åˆ—ï¼‰ã€æŸ¥è©¢å›è¦†æ¨£å¼ã€Visionç”¨Service Accounté¡¯å¼å»ºç«‹
# ============================================

from flask import Flask, request, abort
import os, re, io, json, difflib, logging
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

import gspread
from google.oauth2.service_account import Credentials

from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (
    MessageEvent, TextMessage, ImageMessage,
    TextSendMessage,
)

# ====== ï¼ˆOCRï¼šä½¿ç”¨é¡¯å¼æ†‘è­‰ï¼‰======
_HAS_VISION = False
_vision_client = None
try:
    from google.cloud import vision
    from google.oauth2 import service_account as gcp_service_account
    _HAS_VISION = True
except Exception:
    _HAS_VISION = False
# ==================================

# ============================================
# åŸºæœ¬è¨­å®š
# ============================================
app = Flask(__name__)
app.logger.setLevel(logging.INFO)

# ---- ç’°å¢ƒè®Šæ•¸ ----
SHEET_ID = os.getenv("SHEET_ID", "").strip()

MAIN_SHEET_NAME = os.getenv("MAIN_SHEET_NAME", "å¯„æ›¸ä»»å‹™")
BOOK_MASTER_SHEET_NAME = os.getenv("BOOK_MASTER_SHEET_NAME", "æ›¸ç›®ä¸»æª”")
ZIPREF_SHEET_NAME = os.getenv("ZIPREF_SHEET_NAME", "éƒµéå€è™Ÿåƒç…§è¡¨")
STOCK_IN_SHEET_NAME = os.getenv("STOCK_IN_SHEET_NAME", "å…¥åº«æ˜ç´°")
HISTORY_SHEET_NAME = os.getenv("HISTORY_SHEET_NAME", "æ­·å²ç´€éŒ„")

FUZZY_THRESHOLD = float(os.getenv("FUZZY_THRESHOLD", "0.6"))
QUERY_DAYS = int(os.getenv("QUERY_DAYS", "30"))
PHONE_SUFFIX_MATCH = int(os.getenv("PHONE_SUFFIX_MATCH", "9"))
WRITE_ZIP_TO_ADDRESS = os.getenv("WRITE_ZIP_TO_ADDRESS", "true").lower() == "true"
LOG_OCR_RAW = os.getenv("LOG_OCR_RAW", "true").lower() == "true"

LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET", "")
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "")

if not LINE_CHANNEL_SECRET or not LINE_CHANNEL_ACCESS_TOKEN:
    raise RuntimeError("Missing LINE credentials.")

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

TZ = ZoneInfo("Asia/Taipei")

# ============================================
# åŠŸèƒ½ Dï¼šGoogle Sheets é€£ç·š + è¡¨é ­å°æ‡‰
# ============================================
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]

def _build_gspread_client():
    # å…©ç¨®å–å¾— service account æ†‘è­‰çš„æ–¹æ³•ï¼šæª”æ¡ˆæˆ–ç’°å¢ƒè®Šæ•¸
    json_path = "service_account.json"
    if os.path.exists(json_path):
        creds = Credentials.from_service_account_file(json_path, scopes=SCOPES)
        return gspread.authorize(creds)
    sa_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON", "")
    if not sa_json:
        raise RuntimeError("Missing service account credentials. Provide service_account.json OR env GOOGLE_SERVICE_ACCOUNT_JSON.")
    creds = Credentials.from_service_account_info(json.loads(sa_json), scopes=SCOPES)
    return gspread.authorize(creds)

gc = _build_gspread_client()
ss = gc.open_by_key(SHEET_ID)

def _ws(name: str):
    return ss.worksheet(name)

def _get_header_map(ws):
    """å›å‚³ {æ¬„å: index(1-based)}ï¼›è‡ªå‹•å°ç…§ç›®å‰è¡¨é ­ï¼Œé¿å…æ¬„ä½é †åºå·®ç•°ã€‚"""
    header = ws.row_values(1)
    hmap = {}
    for idx, title in enumerate(header, start=1):
        t = str(title).strip()
        if t:
            hmap[t] = idx
    return hmap

def _col_idx(hmap, key, default_idx):
    """ä¾è¡¨é ­åç¨±æ‰¾æ¬„ä½ï¼Œæ‰¾ä¸åˆ°å°±ç”¨é è¨­åºï¼ˆä»¥ç›®å‰è¦æ ¼ç‚ºæº–ï¼‰ã€‚"""
    return hmap.get(key, default_idx)

# ============================================
# åŠŸèƒ½ Fï¼šå·¥å…·èˆ‡æ ¼å¼åŒ–
# ============================================
def now_str_min():
    return datetime.now(TZ).strftime("%Y-%m-%d %H:%M")

def today_str():
    return datetime.now(TZ).strftime("%Y-%m-%d")

def normalize_phone(s: str) -> str | None:
    digits = re.sub(r"\D+", "", s or "")
    if len(digits) == 10 and digits.startswith("09"):
        return digits
    return None

def parse_kv_lines(text: str):
    """
    å°‡å¤šè¡Œæ–‡å­—ç”¨ã€Œï¼šã€ã€ã€Œ:ã€ç­‰åˆ‡å‡º key/valueï¼Œå›å‚³ dictï¼ˆä¸åšå¼·åˆ¶éµåï¼‰ã€‚
    """
    data = {}
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    for ln in lines:
        if ln.startswith("#"):  # æŒ‡ä»¤è¡Œç•¥é
            continue
        if "ï¼š" in ln:
            k, v = ln.split("ï¼š", 1)
        elif ":" in ln:
            k, v = ln.split(":", 1)
        else:
            # ç„¡æ³•è¾¨è­˜çš„è¡Œä¿ç•™ï¼Œå¾Œé¢ç•¶ä½œã€Œæ¥­å‹™å‚™è¨»ã€å€™é¸
            k, v = "_free_", ln
        k = k.strip()
        v = v.strip()
        data.setdefault(k, []).append(v)
    return data

def detect_delivery_method(text: str) -> str | None:
    s = (text or "").lower().replace("â€”", "-").replace("ï¼", "/")
    # æ”¯æ´æ¨¡ç³Šé—œéµå­—
    if any(k in s for k in ["7-11", "7/11", "7ï¼11", "7â€“11", "711", "å°ä¸ƒ"]):
        return "7-11"
    if "å…¨å®¶" in s or "family" in s:
        return "å…¨å®¶"
    if "èŠçˆ¾å¯Œ" in s or "hi-life" in s or "hilife" in s:
        return "èŠçˆ¾å¯Œ"
    if "ok" in s or "okè¶…å•†" in s:
        return "OK"
    if "å®…é…" in s or "é»‘è²“" in s or "å®…æ€¥ä¾¿" in s:
        return "å®…é…"
    return None  # æœªåµæ¸¬â†’ç•™ç™½

# ============================================
# åŠŸèƒ½ Eï¼šéƒµéå€è™ŸæŸ¥æ‰¾ï¼ˆå‰ç½®ï¼‰
# ============================================
_zip_cache = None
def _load_zipref():
    """è®€å–éƒµéå€è™Ÿè¡¨ï¼Œåšç°¡å–®çš„ã€Œæœ€é•·å‰ç¶´ã€åŒ¹é…ã€‚å®¹éŒ¯å¤šç¨®æ¬„ä½å‘½åã€‚"""
    global _zip_cache
    if _zip_cache is not None:
        return _zip_cache
    try:
        ws = _ws(ZIPREF_SHEET_NAME)
        rows = ws.get_all_values()
        header = rows[0] if rows else []
        zi, ai = None, None
        for i, name in enumerate(header):
            n = str(name).strip()
            if zi is None and re.search(r"éƒµéå€è™Ÿ|éƒµé|zip|ZIP", n, re.I):
                zi = i
            if ai is None and re.search(r"åœ°å€|è·¯|å€|é„‰|é®|æ‘|é‡Œ|æ®µ|å··|å¸‚|ç¸£", n):
                ai = i
        if zi is None or ai is None:
            zi = 1
            ai = 0
        pairs = []
        for r in rows[1:]:
            try:
                prefix = (r[ai] if ai < len(r) else "").strip()
                z = (r[zi] if zi < len(r) else "").strip()
                if prefix and re.fullmatch(r"\d{3}(\d{2})?", z):
                    pairs.append((prefix, z))
            except Exception:
                continue
        pairs.sort(key=lambda x: len(x[0]), reverse=True)
        _zip_cache = pairs
        return _zip_cache
    except Exception as e:
        app.logger.info(f"[ZIPREF] Load failed: {e}")
        _zip_cache = []
        return _zip_cache

def lookup_zip(address: str) -> str | None:
    if not address:
        return None
    pairs = _load_zipref()
    a = address.strip()
    for prefix, z in pairs:
        if a.startswith(prefix):
            return z
    return None

# ============================================
# åŠŸèƒ½ Bï¼šæ›¸åæ¯”å°ï¼ˆæ­£å¼å / åˆ¥å / æ¨¡ç³Šï¼‰
# ============================================
def load_book_master():
    ws = _ws(BOOK_MASTER_SHEET_NAME)
    rows = ws.get_all_values()
    if not rows:
        return []
    header = rows[0]
    # ä¸»è¦æ¬„ä½æ¨æ¸¬ï¼šA=æ˜¯å¦å•Ÿç”¨ã€B=æ›¸ç±åç¨±ã€K=æ¨¡ç³Šæ¯”å°æ›¸å
    use_idx = 0
    name_idx = 1
    alias_idx = None
    for i, col in enumerate(header):
        t = str(col).strip()
        if re.search(r"æ¨¡ç³Š|åˆ¥å|æ¯”å°", t):
            alias_idx = i
    data = []
    for r in rows[1:]:
        try:
            enabled = str(r[use_idx]).strip()
            if enabled != "ä½¿ç”¨ä¸­":
                continue
            name = (r[name_idx] if name_idx < len(r) else "").strip()
            alias_raw = (r[alias_idx] if alias_idx is not None and alias_idx < len(r) else "").strip()
            aliases = []
            if alias_raw:
                aliases = re.split(r"[ã€,\s\|ï¼/]+", alias_raw)
                aliases = [a.strip() for a in aliases if a.strip()]
            data.append({
                "name": name,
                "aliases": aliases
            })
        except Exception:
            continue
    return data

def resolve_book_name(user_input: str):
    """
    å›å‚³ (æ­£å¼æ›¸å, ä¾†æºå‹æ…‹)ï¼›ä¾†æºå‹æ…‹ï¼šexact/alias/fuzzy
    è‹¥ç„¡æ³•å”¯ä¸€æ±ºå®šï¼Œå›å‚³ (None, 'ambiguous' or 'notfound', å€™é¸æ¸…å–®)
    """
    src = (user_input or "").strip()
    if not src:
        return (None, "notfound", [])
    books = load_book_master()
    # 1) å®Œå…¨æ¯”å°ï¼ˆæ­£å¼å or åˆ¥åï¼‰
    exact = [b for b in books if src.lower() == b["name"].lower()]
    if exact:
        return (exact[0]["name"], "exact", None)
    for b in books:
        if any(src.lower() == a.lower() for a in b["aliases"]):
            return (b["name"], "alias", None)
    # 2) æ¨¡ç³Šæ¯”å°ï¼ˆå° æ­£å¼å + åˆ¥åï¼‰
    cand = []
    universe = []
    reverse_map = {}
    for b in books:
        universe.append(b["name"])
        reverse_map[b["name"]] = b["name"]
        for a in b["aliases"]:
            universe.append(a)
            reverse_map[a] = b["name"]
    matches = difflib.get_close_matches(src, universe, n=5, cutoff=FUZZY_THRESHOLD)
    if not matches:
        return (None, "notfound", [])
    # æ˜ å°„å›æ­£å¼åä¸¦å»é‡
    formal = []
    for m in matches:
        fm = reverse_map.get(m)
        if fm and fm not in formal:
            formal.append(fm)
    if len(formal) == 1:
        return (formal[0], "fuzzy", None)
    # å¤šç­†å€™é¸ï¼Œè«‹ä½¿ç”¨è€…æ›´æ˜ç¢º
    return (None, "ambiguous", formal)

# ============================================
# åŠŸèƒ½ Gï¼šVision Clientï¼ˆé¡¯å¼æ†‘è­‰å»ºç«‹ï¼Œé¿å… ADC éŒ¯èª¤ï¼‰
# ============================================
def _build_vision_client():
    global _HAS_VISION, _vision_client
    if not _HAS_VISION:
        return None
    try:
        json_path = "service_account.json"
        creds = None
        if os.path.exists(json_path):
            creds = gcp_service_account.Credentials.from_service_account_file(json_path)
        else:
            sa_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON", "")
            if not sa_json:
                raise RuntimeError("Missing GOOGLE_SERVICE_ACCOUNT_JSON for Vision client.")
            creds = gcp_service_account.Credentials.from_service_account_info(json.loads(sa_json))
        _vision_client = vision.ImageAnnotatorClient(credentials=creds)
        return _vision_client
    except Exception as e:
        app.logger.info(f"[VISION] init failed: {e}")
        _HAS_VISION = False
        return None

_vision_client = _build_vision_client()

# ============================================
# åŠŸèƒ½ Aï¼šæ–‡å­—è¨Šæ¯è™•ç†ï¼ˆ#å¯„æ›¸ / #å¯„æ›¸éœ€æ±‚ã€#æŸ¥è©¢å¯„æ›¸ / #æŸ¥å¯„æ›¸ï¼‰
# ============================================
def _gen_next_record_id(ws, header_map):
    colA = _col_idx(header_map, "ç´€éŒ„ID", 1)
    values = ws.col_values(colA)[1:]  # è·³éè¡¨é ­
    max_no = 0
    for v in values:
        m = re.fullmatch(r"R(\d{4})", str(v).strip())
        if m:
            n = int(m.group(1))
            if n > max_no:
                max_no = n
    nxt = max_no + 1
    return f"R{nxt:04d}"

def _build_insert_row(ws, data, who_display_name):
    """
    data éœ€åŒ…å«ï¼šname, phone, address, book_formal, raw_text, delivery, biz_note
    ä¾ç…§ç›®å‰è¡¨é ­ï¼ˆA~Mï¼‰å›å‚³å¯æ’å…¥çš„åˆ—è¡¨ï¼ˆUSER_ENTEREDï¼‰ã€‚
    æ¬„ä½å®šç¾©ï¼ˆä½ æœ€æ–°è¦æ ¼ï¼‰ï¼š
    Aç´€éŒ„ID Bå»ºå–®æ—¥æœŸ Cå»ºå–®äºº Då­¸å“¡å§“å Eå­¸å“¡é›»è©± Få¯„é€åœ°å€
    Gæ›¸ç±åç¨± Hæ¥­å‹™å‚™è¨» Iå¯„é€æ–¹å¼ Jå¯„å‡ºæ—¥æœŸ Kè¨—é‹å–®è™Ÿ Lç¶“æ‰‹äºº Må¯„é€ç‹€æ…‹
    """
    hmap = _get_header_map(ws)
    header_len = len(ws.row_values(1))
    # é è¨­ç´¢å¼•
    idxA = _col_idx(hmap, "ç´€éŒ„ID", 1)
    idxB = _col_idx(hmap, "å»ºå–®æ—¥æœŸ", 2)
    idxC = _col_idx(hmap, "å»ºå–®äºº", 3)
    idxD = _col_idx(hmap, "å­¸å“¡å§“å", 4)
    idxE = _col_idx(hmap, "å­¸å“¡é›»è©±", 5)
    idxF = _col_idx(hmap, "å¯„é€åœ°å€", 6)
    idxG = _col_idx(hmap, "æ›¸ç±åç¨±", 7)
    idxH = _col_idx(hmap, "æ¥­å‹™å‚™è¨»", 8)
    idxI = _col_idx(hmap, "å¯„é€æ–¹å¼", 9)
    idxJ = _col_idx(hmap, "å¯„å‡ºæ—¥æœŸ", 10)
    idxK = _col_idx(hmap, "è¨—é‹å–®è™Ÿ", 11)
    idxL = _col_idx(hmap, "ç¶“æ‰‹äºº", 12)
    idxM = _col_idx(hmap, "å¯„é€ç‹€æ…‹", 13)

    total_cols = max(header_len, idxM)
    row = [""] * total_cols

    rid = _gen_next_record_id(ws, hmap)
    row[idxA-1] = rid
    row[idxB-1] = now_str_min()
    row[idxC-1] = who_display_name or "LINEä½¿ç”¨è€…"
    row[idxD-1] = data.get("name","")
    # æ‰‹æ©Ÿä»¥æ–‡å­—å‹æ…‹å­˜ï¼ˆé¿å…å‰å°0è¢«åƒï¼‰ï¼šåœ¨å€¼å‰åŠ å–®å¼•è™Ÿ
    phone = data.get("phone","")
    row[idxE-1] = f"'{phone}" if phone else ""
    address = data.get("address","")

    # å®…é…æ‰è£œéƒµéå€è™Ÿï¼›è¶…å•†å¯ä¸å¼·åˆ¶é–€ç‰Œ
    if WRITE_ZIP_TO_ADDRESS and (data.get("delivery") in (None, "", "å®…é…")) and address:
        z = lookup_zip(address)
        if z and not re.match(r"^\d{3}", address):
            address = f"{z}{address}"
    row[idxF-1] = address

    row[idxG-1] = data.get("book_formal","")
    row[idxH-1] = data.get("biz_note","")
    row[idxI-1] = data.get("delivery") or ""  # æœªåµæ¸¬â†’ç•™ç™½
    row[idxJ-1] = ""  # å‡ºè²¨æ™‚å¡«
    row[idxK-1] = ""  # å–®è™Ÿ
    row[idxL-1] = ""  # ç¶“æ‰‹äººï¼ˆOCR æ™‚å¡«ï¼‰
    row[idxM-1] = "å¾…è™•ç†"

    return row, {"rid": rid}

def _parse_new_order_text(raw_text: str):
    """
    è§£æ #å¯„æ›¸ / #å¯„æ›¸éœ€æ±‚ æ–‡å­—ï¼Œè¼¸å‡º dict èˆ‡éŒ¯èª¤æ¸…å–®
    å¿…å¡«ï¼šå§“åã€é›»è©±ã€æ›¸åï¼›åœ°å€ï¼ˆè‹¥éè¶…å•†ï¼‰
    éå§“å/é›»è©±/åœ°å€/æ›¸å/å¯„é€æ–¹å¼ â†’ æ¥­å‹™å‚™è¨»
    """
    data = parse_kv_lines(raw_text)
    merged_text = "\n".join(sum(data.values(), []))  # ç”¨æ–¼å¯„é€æ–¹å¼åµæ¸¬

    # 1) å§“åï¼ˆå¸¸è¦‹éµåŒ…å«ï¼šå§“å/å­¸å“¡å§“å/æ”¶ä»¶äººï¼‰
    name = None
    for k in list(data.keys()):
        if any(x in k for x in ["å§“å","å­¸å“¡","æ”¶ä»¶äºº","åå­—","è²´å§“"]):
            name = "ã€".join(data.pop(k))
            break

    # 2) é›»è©±
    phone = None
    for k in list(data.keys()):
        if "é›»è©±" in k:
            for v in data.pop(k):
                p = normalize_phone(v)
                if p:
                    phone = p
                    break
            break

    # 3) åœ°å€
    address = None
    for k in list(data.keys()):
        if any(x in k for x in ["å¯„é€åœ°å€","åœ°å€","æ”¶ä»¶åœ°å€","é…é€åœ°å€"]):
            address = " ".join(data.pop(k))
            address = address.replace(" ", "")
            break

    # 4) æ›¸å
    book_raw = None
    for k in list(data.keys()):
        if any(x in k for x in ["æ›¸","æ›¸å","æ•™æ","æ›¸ç±åç¨±"]):
            book_raw = " ".join(data.pop(k)).strip()
            break

    # 5) å¯„é€æ–¹å¼ï¼ˆåµæ¸¬ï¼‰
    delivery = detect_delivery_method(merged_text)

    # 6) å…¶é¤˜ â†’ æ¥­å‹™å‚™è¨»
    others = []
    for k, arr in data.items():
        for v in arr:
            if k != "_free_":
                others.append(f"{k}ï¼š{v}")
            else:
                others.append(v)
    biz_note = " / ".join([x for x in others if x.strip()])

    # é©—è­‰å¿…å¡«ï¼ˆè‹¥éè¶…å•†éœ€åœ°å€ï¼‰
    errors = []
    if not name: errors.append("ç¼ºå°‘ã€å§“åã€‘")
    if not phone: errors.append("é›»è©±æ ¼å¼éŒ¯èª¤ï¼ˆéœ€ 09 é–‹é ­ 10 ç¢¼ï¼‰")
    if not book_raw: errors.append("ç¼ºå°‘ã€æ›¸åã€‘")
    if delivery not in ["7-11","å…¨å®¶","OK","èŠçˆ¾å¯Œ"] and not address:
        errors.append("ç¼ºå°‘ã€å¯„é€åœ°å€ã€‘ï¼ˆéè¶…å•†å¿…å¡«ï¼‰")

    return {
        "name": name,
        "phone": phone,
        "address": address,
        "book_raw": book_raw,
        "biz_note": biz_note,
        "delivery": delivery,  # æœªåµæ¸¬â†’None
        "raw_text": raw_text
    }, errors

def _handle_new_order(event, text):
    # å˜—è©¦å–å¾— LINE é¡¯ç¤ºåç¨±
    try:
        profile = line_bot_api.get_profile(event.source.user_id)
        display_name = profile.display_name
    except Exception:
        display_name = "LINEä½¿ç”¨è€…"

    parsed, errs = _parse_new_order_text(text)
    if errs:
        msg = "âŒ å»ºæª”å¤±æ•—ï¼š\n- " + "\n- ".join(errs)
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
        return

    # æ›¸åè§£æ â†’ æ­£å¼å
    book_formal, kind, extra = resolve_book_name(parsed["book_raw"])
    if not book_formal:
        if kind == "ambiguous" and extra:
            msg = "â— æ›¸åæœ‰å¤šå€‹å¯èƒ½ï¼Œè«‹æ›´æ˜ç¢ºï¼š\n" + "ã€".join(extra[:10])
        else:
            msg = "âŒ æ‰¾ä¸åˆ°å°æ‡‰çš„æ›¸åï¼Œè«‹ç¢ºèªæˆ–è£œå……é—œéµå­—ã€‚"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
        return

    parsed["book_formal"] = book_formal

    ws = _ws(MAIN_SHEET_NAME)
    row, meta = _build_insert_row(ws, parsed, display_name)

    # â˜… æ’å…¥ç¬¬ 2 åˆ—ï¼ˆä¸Šæ–°ä¸‹èˆŠï¼‰
    ws.insert_row(row, index=2, value_input_option="USER_ENTERED")

    # æˆåŠŸå›è¦†
    resp = (
        "âœ… å·²æˆåŠŸå»ºæª”\n"
        f"ç´€éŒ„IDï¼š{meta['rid']}\n"
        f"å»ºå–®æ—¥æœŸï¼š{now_str_min()}\n"
        f"å§“åï¼š{parsed['name']}ï½œé›»è©±ï¼š{parsed['phone']}\n"
        f"åœ°å€ï¼š{row[_get_header_map(ws).get('å¯„é€åœ°å€',6)-1]}\n"
        f"æ›¸ç±ï¼š{book_formal}\n"
        f"ç‹€æ…‹ï¼šå¾…è™•ç†"
    )
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=resp))

def _handle_query(event, text):
    # å»æ‰æŒ‡ä»¤å­—é ­
    q = re.sub(r"^#(æŸ¥è©¢å¯„æ›¸|æŸ¥å¯„æ›¸)\s*", "", text.strip())

    ws = _ws(MAIN_SHEET_NAME)
    h = _get_header_map(ws)
    idxB = _col_idx(h, "å»ºå–®æ—¥æœŸ", 2)
    idxD = _col_idx(h, "å­¸å“¡å§“å", 4)
    idxE = _col_idx(h, "å­¸å“¡é›»è©±", 5)
    idxG = _col_idx(h, "æ›¸ç±åç¨±", 7)
    idxI = _col_idx(h, "å¯„é€æ–¹å¼", 9)
    idxJ = _col_idx(h, "å¯„å‡ºæ—¥æœŸ", 10)
    idxK = _col_idx(h, "è¨—é‹å–®è™Ÿ", 11)
    idxM = _col_idx(h, "å¯„é€ç‹€æ…‹", 13)

    rows = ws.get_all_values()[1:]
    since = datetime.now(TZ) - timedelta(days=QUERY_DAYS)

    # åˆ¤æ–·å§“å or é›»è©±
    phone_digits = re.sub(r"\D+","", q)
    is_phone = len(phone_digits) >= 7

    results = []
    for r in rows:
        try:
            # æ™‚é–“çª—
            dt_str = r[idxB-1].strip()
            dt = None
            if dt_str:
                try:
                    dt = datetime.strptime(dt_str[:16], "%Y-%m-%d %H:%M").replace(tzinfo=TZ)
                except Exception:
                    dt = None
            if dt and dt < since:
                continue

            # ç¯©é¸
            if is_phone:
                cand = re.sub(r"\D+","", r[idxE-1])
                if len(cand) >= PHONE_SUFFIX_MATCH and phone_digits[-PHONE_SUFFIX_MATCH:] == cand[-PHONE_SUFFIX_MATCH:]:
                    results.append(r)
            else:
                if q and q in r[idxD-1]:
                    results.append(r)
        except Exception:
            continue

    if not results:
        msg = "âŒ æŸ¥ç„¡è¿‘ 30 å¤©å…§çš„å¯„æ›¸ç´€éŒ„ï¼Œè«‹ç¢ºèªå§“åæˆ–é›»è©±æ˜¯å¦æ­£ç¢ºã€‚"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
        return

    # æ–°â†’èˆŠæ’åºï¼ˆä»¥å»ºå–®æ—¥æœŸå­—ä¸²æ’åºï¼‰
    def sort_key(r):
        return r[idxB-1]
    results.sort(key=sort_key, reverse=True)
    results = results[:5]

    # â˜… å›è¦†æ¨£å¼ï¼ˆä¾ç‹€æ…‹åˆ‡æ›ï¼‰
    blocks = []
    for r in results:
        name = r[idxD-1]
        book = r[idxG-1]
        status = (r[idxM-1] or "").strip()
        outd = (r[idxJ-1] or "").strip()
        ship = (r[idxI-1] or "").strip()
        no = (r[idxK-1] or "").strip()

        if status == "å·²è¨—é‹":
            lines = [f"ğŸ“¦ {name} çš„ {book}"]
            if outd:
                lines.append(f"å·²æ–¼ {outd}")
            if ship:
                lines.append(f"ç”± {ship} å¯„å‡º")
            if no:
                lines.append(f"è¨—é‹å–®è™Ÿï¼š{no}")
            blocks.append("\n".join(lines))
        else:
            # å¾…è™•ç†æˆ–å…¶ä»–ç‹€æ…‹ï¼šå–®è¡Œé¡¯ç¤º
            blocks.append(f"ğŸ“¦ {name} çš„ {book} {status or 'å¾…è™•ç†'}")

    msg = "\n\n".join(blocks)
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))

# ============================================
# åŠŸèƒ½ Cï¼šOCR åœ–ç‰‡è™•ç†ï¼ˆå‡ºè²¨å–®â†’å–®è™Ÿå¯«å›/ç‹€æ…‹æ›´æ–°ï¼‰
# ============================================
def _download_line_image_bytes(message_id: str) -> bytes:
    content = line_bot_api.get_message_content(message_id)
    return b"".join(chunk for chunk in content.iter_content())

def _ocr_text_from_bytes(img_bytes: bytes) -> str:
    if not _vision_client:
        raise RuntimeError("Vision ç”¨æˆ¶ç«¯æœªåˆå§‹åŒ–ï¼ˆè«‹ç¢ºèª GOOGLE_SERVICE_ACCOUNT_JSON å·²è¨­å®šï¼Œä¸”å°ˆæ¡ˆå•Ÿç”¨ Vision APIï¼‰ã€‚")
    image = vision.Image(content=img_bytes)
    resp = _vision_client.text_detection(image=image)
    if resp.error.message:
        raise RuntimeError(resp.error.message)
    text = resp.full_text_annotation.text if resp.full_text_annotation else ""
    return text or ""

def _pair_ids_with_numbers(text: str):
    """
    å¾ OCR æ–‡æœ¬æ“·å– Rxxxx èˆ‡ 12ç¢¼å–®è™Ÿï¼Œå˜—è©¦ã€Œå°±è¿‘é…å°ã€ï¼›ä¸è¤‡é›œåŒ–ã€‚
    å›å‚³ï¼š(pairs, leftovers)
    pairs: [(rid, no12)]
    leftovers: è¨Šæ¯åˆ—è¡¨ï¼ˆéœ€äººå·¥ï¼‰
    """
    if not text:
        return [], ["æœªè®€å–åˆ°æ–‡å­—"]
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    if LOG_OCR_RAW:
        app.logger.info(f"[OCR_RAW_OUTPUT] {repr(text[:1000])}")

    rids = []
    nums = []
    for i, ln in enumerate(lines):
        for m in re.finditer(r"R\d{4}", ln):
            rids.append((m.group(), i))
        for m in re.finditer(r"\d{12}", ln):
            nums.append((m.group(), i))

    pairs = []
    used_num = set()
    leftovers = []

    # ç°¡å–®å°±è¿‘ï¼šæ¯å€‹ rid æ‰¾æœ€è¿‘çš„ 12 ç¢¼
    for rid, li in rids:
        chosen = None
        best_dist = 999
        for no, lj in nums:
            if (no, lj) in used_num:
                continue
            d = abs(lj - li)
            if d < best_dist:
                best_dist = d
                chosen = (no, lj)
        if chosen:
            pairs.append((rid, chosen[0]))
            used_num.add(chosen)
        else:
            leftovers.append(f"{rid}ï½œæœªæ‰¾åˆ° 12 ç¢¼å–®è™Ÿ")

    # å¤šå‡ºçš„è™Ÿç¢¼
    for no, lj in nums:
        if (no, lj) not in used_num:
            leftovers.append(f"æœªé…å°å–®è™Ÿï¼š{no}")

    return pairs, leftovers

def _write_ocr_results(pairs, event):
    if not pairs:
        return "â— æœªå¯«å…¥ä»»ä½•è³‡æ–™ï¼ˆæœªæ‰¾åˆ°é…å°ï¼‰"
    ws = _ws(MAIN_SHEET_NAME)
    h = _get_header_map(ws)
    idxA = _col_idx(h, "ç´€éŒ„ID", 1)
    idxJ = _col_idx(h, "å¯„å‡ºæ—¥æœŸ", 10)
    idxK = _col_idx(h, "è¨—é‹å–®è™Ÿ", 11)
    idxL = _col_idx(h, "ç¶“æ‰‹äºº", 12)
    idxM = _col_idx(h, "å¯„é€ç‹€æ…‹", 13)

    # å–å¾—ä¸Šå‚³è€…åç¨±
    try:
        profile = line_bot_api.get_profile(event.source.user_id)
        uploader = profile.display_name or "LINEä½¿ç”¨è€…"
    except Exception:
        uploader = "LINEä½¿ç”¨è€…"

    # å»ºç«‹ç´¢å¼•ï¼šç´€éŒ„ID â†’ row
    all_vals = ws.get_all_values()
    rows = all_vals[1:]
    id2row = {}
    for ridx, r in enumerate(rows, start=2):  # 2 = å«è¡¨é ­
        try:
            rid = r[idxA-1].strip()
            if re.fullmatch(r"R\d{4}", rid):
                id2row[rid] = ridx
        except Exception:
            continue

    updated = []
    for rid, no in pairs:
        row_i = id2row.get(rid)
        if not row_i:
            continue
        # å¯«å…¥ï¼šKå–®è™Ÿã€Jå‡ºè²¨æ—¥=ä»Šæ—¥ã€Lç¶“æ‰‹äººã€Mç‹€æ…‹=å·²è¨—é‹
        # å–®è™Ÿä»¥æ–‡å­—å‹æ…‹å­˜ï¼ˆé¿å…é•·æ•¸å­—è½‰ç§‘å­¸è¨˜è™Ÿï¼‰
        ws.update_cell(row_i, idxK, f"'{no}")
        ws.update_cell(row_i, idxJ, today_str())
        ws.update_cell(row_i, idxL, uploader)
        ws.update_cell(row_i, idxM, "å·²è¨—é‹")
        updated.append((rid, no))

    if not updated:
        return "â— æœªå¯«å…¥ï¼ˆæ‰¾ä¸åˆ°å°æ‡‰çš„ç´€éŒ„IDï¼‰"

    lines = [f"{rid} â†’ {no}" for rid, no in updated]
    return "âœ… å·²æ›´æ–°ï¼š{} ç­†\n{}".format(len(updated), "\n".join(lines))

# ============================================
# LINE Webhook
# ============================================
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature", "")
    body = request.get_data(as_text=True)
    app.logger.info("Request body: " + body)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return "OK"

# =========================
# æ–‡å­—è¨Šæ¯è™•ç†
# =========================
@handler.add(MessageEvent, message=TextMessage)
def handle_text_message(event):
    text = (event.message.text or "").strip()

    # æŒ‡ä»¤ï¼š#å¯„æ›¸ / #å¯„æ›¸éœ€æ±‚
    if text.startswith("#å¯„æ›¸éœ€æ±‚") or text.startswith("#å¯„æ›¸"):
        _handle_new_order(event, text)
        return

    # æŒ‡ä»¤ï¼š#æŸ¥è©¢å¯„æ›¸ / #æŸ¥å¯„æ›¸
    if text.startswith("#æŸ¥è©¢å¯„æ›¸") or text.startswith("#æŸ¥å¯„æ›¸"):
        _handle_query(event, text)
        return

    # å…¶ä»–æ–‡å­—
    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text="è«‹ä½¿ç”¨ï¼š\n#å¯„æ›¸ï¼ˆå»ºç«‹å¯„æ›¸ä»»å‹™ï¼‰\n#æŸ¥å¯„æ›¸ï¼ˆå§“åæˆ–é›»è©±ï¼‰")
    )

# =========================
# åœ–ç‰‡è¨Šæ¯è™•ç†ï¼ˆOCRï¼‰
# =========================
@handler.add(MessageEvent, message=ImageMessage)
def handle_image_message(event):
    try:
        app.logger.info(f"[IMG] æ”¶åˆ°åœ–ç‰‡ user_id={getattr(event.source,'user_id','unknown')} msg_id={event.message.id}")
        img_bytes = _download_line_image_bytes(event.message.id)
        if not _vision_client:
            msg = "âŒ OCR è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼šVision ç”¨æˆ¶ç«¯æœªåˆå§‹åŒ–ï¼ˆè«‹ç¢ºèª GOOGLE_SERVICE_ACCOUNT_JSON å·²è¨­å®šï¼Œä¸”å°ˆæ¡ˆå·²å•Ÿç”¨ Vision APIï¼‰ã€‚"
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
            return

        text = _ocr_text_from_bytes(img_bytes)
        if LOG_OCR_RAW:
            app.logger.info(f"[OCR_TEXT]\n{text}")

        pairs, leftovers = _pair_ids_with_numbers(text)
        resp = _write_ocr_results(pairs, event)

        if leftovers:
            resp += "\n\nâ—ä»¥ä¸‹é …ç›®éœ€äººå·¥æª¢æ ¸ï¼š\n" + "\n".join(leftovers[:10])

        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=resp))
    except Exception as e:
        code = datetime.now(TZ).strftime("%Y%m%d%H%M%S")
        app.logger.exception("[OCR_ERROR]")
        msg = f"âŒ OCR éŒ¯èª¤ï¼ˆä»£ç¢¼ {code}ï¼‰ï¼š{e}"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))

# ============================================
# å¥åº·æª¢æŸ¥
# ============================================
@app.route("/", methods=["GET"])
def index():
    try:
        names = [ws.title for ws in ss.worksheets()]
        return "OK / Worksheets: " + ", ".join(names)
    except Exception as e:
        return f"OK / (Sheets not loaded) {e}"

# ============================================
# æœ¬åœ°åŸ·è¡Œï¼ˆRailway ç”¨ gunicorn å•Ÿå‹•ï¼‰
# ============================================
if __name__ == "__main__":
    port = int(os.getenv("PORT", "8080"))
    app.run(host="0.0.0.0", port=port)

# app.py
# ============================================
# ã€Šå¯„æ›¸ï¼‹é€²éŠ·å­˜ è‡ªå‹•åŒ–æ©Ÿå™¨äººã€‹â€” å®Œæ•´ç‰ˆï¼ˆç§»é™¤åˆªé™¤ç·šï¼›åœ°å€è‡ªå‹•è£œéƒµéå€è™Ÿï¼‰
# æ¶æ§‹ï¼šFlask + LINE Webhook + Google Sheets +ï¼ˆé¸ï¼‰Vision OCR
# ç‰¹é»ï¼š
# - å»ºæª”ã€Œä¸Šæ–°ä¸‹èˆŠã€ï¼ˆInsertDimension inheritFromBefore=Falseï¼Œé¿å…æ ¼å¼é€£å¸¶ï¼‰
# - å¯„é€æ–¹å¼ï¼šåªåµæ¸¬ä¾¿åˆ©å•†åº—ï¼›è‹¥æœªåµæ¸¬ä¸”æœ‰åœ°å€ â†’ è‡ªå‹•è¨­ç‚ºã€Œä¾¿åˆ©å¸¶ã€
# - æ–°å¢å¯„æ›¸ï¼šè‹¥è®€åˆ°åœ°å€ï¼Œ**ä¸€å¾‹å˜—è©¦æŸ¥éƒµéå€è™Ÿä¸¦å‰ç½®åˆ° F æ¬„**
# - æŸ¥è©¢å›è¦†æ¨£å¼ï¼ˆå¾…è™•ç†/å·²è¨—é‹ï¼›é è¨­ä¸é¡¯ç¤ºå·²åˆªé™¤ï¼‰
# - OCR å¯«å›ï¼ˆå–®è™Ÿ/å‡ºè²¨æ—¥/ç¶“æ‰‹äºº/ç‹€æ…‹ï¼‰
# - å–æ¶ˆå¯„æ›¸ï¼ˆè»Ÿåˆªé™¤ï¼‰ï¼š#å–æ¶ˆå¯„æ›¸ï¼ˆæ¬Šé™=å»ºå–®äººåŒåã€Y/N ç¢ºèªï¼›ç„¡åˆªé™¤ç·šï¼Œåªå¯«å‚™è¨»ï¼‹ç‹€æ…‹ï¼‰
# ============================================

from flask import Flask, request, abort
import os, re, io, json, difflib, logging
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

import gspread
from google.oauth2.service_account import Credentials

from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (
    MessageEvent, TextMessage, ImageMessage,
    TextSendMessage,
)

# ====== ï¼ˆOCRï¼šä½¿ç”¨é¡¯å¼æ†‘è­‰ï¼‰======
_HAS_VISION = False
_vision_client = None
try:
    from google.cloud import vision
    from google.oauth2 import service_account as gcp_service_account
    _HAS_VISION = True
except Exception:
    _HAS_VISION = False
# ==================================

app = Flask(__name__)
app.logger.setLevel(logging.INFO)

# ---- ç’°å¢ƒè®Šæ•¸ ----
SHEET_ID = os.getenv("SHEET_ID", "").strip()

MAIN_SHEET_NAME = os.getenv("MAIN_SHEET_NAME", "å¯„æ›¸ä»»å‹™")
BOOK_MASTER_SHEET_NAME = os.getenv("BOOK_MASTER_SHEET_NAME", "æ›¸ç›®ä¸»æª”")
ZIPREF_SHEET_NAME = os.getenv("ZIPREF_SHEET_NAME", "éƒµéå€è™Ÿåƒç…§è¡¨")
STOCK_IN_SHEET_NAME = os.getenv("STOCK_IN_SHEET_NAME", "å…¥åº«æ˜ç´°")
HISTORY_SHEET_NAME = os.getenv("HISTORY_SHEET_NAME", "æ­·å²ç´€éŒ„")

FUZZY_THRESHOLD = float(os.getenv("FUZZY_THRESHOLD", "0.6"))
QUERY_DAYS = int(os.getenv("QUERY_DAYS", "30"))
PHONE_SUFFIX_MATCH = int(os.getenv("PHONE_SUFFIX_MATCH", "9"))
WRITE_ZIP_TO_ADDRESS = os.getenv("WRITE_ZIP_TO_ADDRESS", "true").lower() == "true"
LOG_OCR_RAW = os.getenv("LOG_OCR_RAW", "true").lower() == "true"

LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET", "")
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "")

if not LINE_CHANNEL_SECRET or not LINE_CHANNEL_ACCESS_TOKEN:
    raise RuntimeError("Missing LINE credentials.")

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

TZ = ZoneInfo("Asia/Taipei")

# ============================================
# Google Sheets é€£ç·š + è¡¨é ­å°æ‡‰
# ============================================
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]

def _build_gspread_client():
    json_path = "service_account.json"
    if os.path.exists(json_path):
        creds = Credentials.from_service_account_file(json_path, scopes=SCOPES)
        return gspread.authorize(creds)
    sa_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON", "")
    if not sa_json:
        raise RuntimeError("Missing service account credentials. Provide service_account.json OR env GOOGLE_SERVICE_ACCOUNT_JSON.")
    creds = Credentials.from_service_account_info(json.loads(sa_json), scopes=SCOPES)
    return gspread.authorize(creds)

gc = _build_gspread_client()
ss = gc.open_by_key(SHEET_ID)

def _ws(name: str):
    return ss.worksheet(name)

def _get_header_map(ws):
    header = ws.row_values(1)
    hmap = {}
    for idx, title in enumerate(header, start=1):
        t = str(title).strip()
        if t:
            hmap[t] = idx
    return hmap

def _col_idx(hmap, key, default_idx):
    return hmap.get(key, default_idx)

# ============================================
# å·¥å…·èˆ‡æ ¼å¼åŒ–
# ============================================
def now_str_min():
    return datetime.now(TZ).strftime("%Y-%m-%d %H:%M")

def today_str():
    return datetime.now(TZ).strftime("%Y-%m-%d")

def normalize_phone(s: str):
    digits = re.sub(r"\D+", "", s or "")
    if len(digits) == 10 and digits.startswith("09"):
        return digits
    return None

def parse_kv_lines(text: str):
    data = {}
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    for ln in lines:
        if ln.startswith("#"):
            continue
        if "ï¼š" in ln:
            k, v = ln.split("ï¼š", 1)
        elif ":" in ln:
            k, v = ln.split(":", 1)
        else:
            k, v = "_free_", ln
        k = k.strip()
        v = v.strip()
        data.setdefault(k, []).append(v)
    return data

def col_to_letter(col: int) -> str:
    s = ""
    while col > 0:
        col, r = divmod(col - 1, 26)
        s = chr(r + 65) + s
    return s

# ============================================
# å¯„é€æ–¹å¼åµæ¸¬ï¼ˆåªåµæ¸¬ä¾¿åˆ©å•†åº—ï¼›å…¶é¤˜äº¤ç”±å¾ŒçºŒè¦å‰‡ï¼‰
# ============================================
def detect_delivery_method(text: str):
    s = (text or "").lower().replace("â€”", "-").replace("ï¼", "/")
    if any(k in s for k in ["7-11","7/11","7ï¼11","7â€“11","711","å°ä¸ƒ"]): return "7-11"
    if "å…¨å®¶" in s or "family" in s: return "å…¨å®¶"
    if "èŠçˆ¾å¯Œ" in s or "hi-life" in s or "hilife" in s: return "èŠçˆ¾å¯Œ"
    if "ok" in s or "okè¶…å•†" in s: return "OK"
    return None

# ============================================
# éƒµéå€è™ŸæŸ¥æ‰¾ï¼ˆå‰ç½®ï¼‰
# ============================================
_zip_cache = None
def _load_zipref():
    global _zip_cache
    if _zip_cache is not None:
        return _zip_cache
    try:
        ws = _ws(ZIPREF_SHEET_NAME)
        rows = ws.get_all_values()
        header = rows[0] if rows else []
        zi, ai = None, None
        for i, name in enumerate(header):
            n = str(name).strip()
            if zi is None and re.search(r"éƒµéå€è™Ÿ|éƒµé|zip|ZIP", n, re.I): zi = i
            if ai is None and re.search(r"åœ°å€|è·¯|å€|é„‰|é®|æ‘|é‡Œ|æ®µ|å··|å¸‚|ç¸£", n): ai = i
        if zi is None or ai is None:
            zi, ai = 1, 0
        pairs = []
        for r in rows[1:]:
            try:
                prefix = (r[ai] if ai < len(r) else "").strip()
                z = (r[zi] if zi < len(r) else "").strip()
                if prefix and re.fullmatch(r"\d{3}(\d{2})?", z):
                    pairs.append((prefix, z))
            except Exception:
                continue
        pairs.sort(key=lambda x: len(x[0]), reverse=True)
        _zip_cache = pairs
        return _zip_cache
    except Exception as e:
        app.logger.info(f"[ZIPREF] Load failed: {e}")
        _zip_cache = []
        return _zip_cache

def lookup_zip(address: str):
    if not address:
        return None
    pairs = _load_zipref()
    a = address.strip()
    for prefix, z in pairs:
        if a.startswith(prefix):
            return z
    return None

# ============================================
# æ›¸åæ¯”å°
# ============================================
def load_book_master():
    ws = _ws(BOOK_MASTER_SHEET_NAME)
    rows = ws.get_all_values()
    if not rows:
        return []
    header = rows[0]
    use_idx = 0
    name_idx = 1
    alias_idx = None
    for i, col in enumerate(header):
        t = str(col).strip()
        if re.search(r"æ¨¡ç³Š|åˆ¥å|æ¯”å°", t):
            alias_idx = i
    data = []
    for r in rows[1:]:
        try:
            enabled = str(r[use_idx]).strip()
            if enabled != "ä½¿ç”¨ä¸­":
                continue
            name = (r[name_idx] if name_idx < len(r) else "").strip()
            alias_raw = (r[alias_idx] if alias_idx is not None and alias_idx < len(r) else "").strip()
            aliases = []
            if alias_raw:
                aliases = re.split(r"[ã€,\s\|ï¼/]+", alias_raw)
                aliases = [a.strip() for a in aliases if a.strip()]
            data.append({"name": name, "aliases": aliases})
        except Exception:
            continue
    return data

def resolve_book_name(user_input: str):
    src = (user_input or "").strip()
    if not src:
        return (None, "notfound", [])
    books = load_book_master()
    exact = [b for b in books if src.lower() == b["name"].lower()]
    if exact:
        return (exact[0]["name"], "exact", None)
    for b in books:
        if any(src.lower() == a.lower() for a in b["aliases"]):
            return (b["name"], "alias", None)
    universe, reverse_map = [], {}
    for b in books:
        universe.append(b["name"]); reverse_map[b["name"]] = b["name"]
        for a in b["aliases"]:
            universe.append(a); reverse_map[a] = b["name"]
    matches = difflib.get_close_matches(src, universe, n=5, cutoff=FUZZY_THRESHOLD)
    if not matches:
        return (None, "notfound", [])
    formal = []
    for m in matches:
        fm = reverse_map.get(m)
        if fm and fm not in formal:
            formal.append(fm)
    if len(formal) == 1:
        return (formal[0], "fuzzy", None)
    return (None, "ambiguous", formal)

# ============================================
# Vision Clientï¼ˆé¡¯å¼æ†‘è­‰å»ºç«‹ï¼Œé¿å… ADC éŒ¯èª¤ï¼‰
# ============================================
def _build_vision_client():
    global _HAS_VISION, _vision_client
    if not _HAS_VISION:
        return None
    try:
        json_path = "service_account.json"
        creds = None
        if os.path.exists(json_path):
            creds = gcp_service_account.Credentials.from_service_account_file(json_path)
        else:
            sa_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON", "")
            if not sa_json:
                raise RuntimeError("Missing GOOGLE_SERVICE_ACCOUNT_JSON for Vision client.")
            creds = gcp_service_account.Credentials.from_service_account_info(json.loads(sa_json))
        _vision_client = vision.ImageAnnotatorClient(credentials=creds)
        return _vision_client
    except Exception as e:
        app.logger.info(f"[VISION] init failed: {e}")
        _HAS_VISION = False
        return None

_vision_client = _build_vision_client()

# ============================================
# å»ºæª”è¼”åŠ©
# ============================================
def _gen_next_record_id(ws, header_map):
    colA = _col_idx(header_map, "ç´€éŒ„ID", 1)
    values = ws.col_values(colA)[1:]
    max_no = 0
    for v in values:
        m = re.fullmatch(r"R(\d{4})", str(v).strip())
        if m:
            n = int(m.group(1))
            if n > max_no:
                max_no = n
    return f"R{max_no+1:04d}"

def _build_insert_row(ws, data, who_display_name):
    """
    æ¬„ä½ï¼šAç´€éŒ„ID Bå»ºå–®æ—¥æœŸ Cå»ºå–®äºº Då­¸å“¡å§“å Eå­¸å“¡é›»è©± Få¯„é€åœ°å€
          Gæ›¸ç±åç¨± Hæ¥­å‹™å‚™è¨» Iå¯„é€æ–¹å¼ Jå¯„å‡ºæ—¥æœŸ Kè¨—é‹å–®è™Ÿ Lç¶“æ‰‹äºº Må¯„é€ç‹€æ…‹
    """
    hmap = _get_header_map(ws)
    header_len = len(ws.row_values(1))
    idxA = _col_idx(hmap, "ç´€éŒ„ID", 1)
    idxB = _col_idx(hmap, "å»ºå–®æ—¥æœŸ", 2)
    idxC = _col_idx(hmap, "å»ºå–®äºº", 3)
    idxD = _col_idx(hmap, "å­¸å“¡å§“å", 4)
    idxE = _col_idx(hmap, "å­¸å“¡é›»è©±", 5)
    idxF = _col_idx(hmap, "å¯„é€åœ°å€", 6)
    idxG = _col_idx(hmap, "æ›¸ç±åç¨±", 7)
    idxH = _col_idx(hmap, "æ¥­å‹™å‚™è¨»", 8)
    idxI = _col_idx(hmap, "å¯„é€æ–¹å¼", 9)
    idxJ = _col_idx(hmap, "å¯„å‡ºæ—¥æœŸ", 10)
    idxK = _col_idx(hmap, "è¨—é‹å–®è™Ÿ", 11)
    idxL = _col_idx(hmap, "ç¶“æ‰‹äºº", 12)
    idxM = _col_idx(hmap, "å¯„é€ç‹€æ…‹", 13)

    total_cols = max(header_len, idxM)
    row = [""] * total_cols

    rid = _gen_next_record_id(ws, hmap)
    row[idxA-1] = rid
    row[idxB-1] = now_str_min()
    row[idxC-1] = who_display_name or "LINEä½¿ç”¨è€…"
    row[idxD-1] = data.get("name","")
    phone = data.get("phone","")
    row[idxE-1] = f"'{phone}" if phone else ""
    address = data.get("address","")

    # âœ… ä¸€å¾‹å˜—è©¦è£œéƒµéå€è™Ÿï¼ˆè‹¥èƒ½å°ä¸Šä¸”ç›®å‰æ²’3ç¢¼é–‹é ­ï¼‰
    if WRITE_ZIP_TO_ADDRESS and address:
        z = lookup_zip(address)
        if z and not re.match(r"^\d{3}", address):
            address = f"{z}{address}"
    row[idxF-1] = address

    row[idxG-1] = data.get("book_formal","")
    row[idxH-1] = data.get("biz_note","")
    row[idxI-1] = data.get("delivery") or ""
    row[idxJ-1] = ""
    row[idxK-1] = ""
    row[idxL-1] = ""
    row[idxM-1] = "å¾…è™•ç†"

    return row, {"rid": rid}

# â˜… æ’å…¥ç¬¬2åˆ—ä¸ç¹¼æ‰¿æ ¼å¼
def _insert_row_values_no_inherit(ws, row_values, index=2):
    ss.batch_update({
        "requests": [{
            "insertDimension": {
                "range": {
                    "sheetId": ws.id,
                    "dimension": "ROWS",
                    "startIndex": index - 1,
                    "endIndex": index
                },
                "inheritFromBefore": False
            }
        }]
    })
    header_len = len(ws.row_values(1)) or 13
    last_col = max(header_len, len(row_values))
    if len(row_values) < last_col:
        row_values = row_values + [""] * (last_col - len(row_values))
    rng = f"A{index}:{col_to_letter(last_col)}{index}"
    ws.update(rng, [row_values], value_input_option="USER_ENTERED")

# ============================================
# è§£æï¼‹æŒ‡ä»¤è™•ç†ï¼ˆå»ºç«‹å¯„æ›¸ï¼‰
# ============================================
def _parse_new_order_text(raw_text: str):
    data = parse_kv_lines(raw_text)

    # 1) å§“å
    name = None
    for k in list(data.keys()):
        if any(x in k for x in ["å§“å","å­¸å“¡","æ”¶ä»¶äºº","åå­—","è²´å§“"]):
            name = "ã€".join(data.pop(k))
            break

    # 2) é›»è©±
    phone = None
    for k in list(data.keys()):
        if "é›»è©±" in k:
            for v in data.pop(k):
                p = normalize_phone(v)
                if p:
                    phone = p
                    break
            break

    # 3) åœ°å€
    address = None
    for k in list(data.keys()):
        if any(x in k for x in ["å¯„é€åœ°å€","åœ°å€","æ”¶ä»¶åœ°å€","é…é€åœ°å€"]):
            address = " ".join(data.pop(k))
            address = address.replace(" ", "")
            break

    # 4) æ›¸å
    book_raw = None
    for k in list(data.keys()):
        if any(x in k for x in ["æ›¸","æ›¸å","æ•™æ","æ›¸ç±åç¨±"]):
            book_raw = " ".join(data.pop(k)).strip()
            break

    # åˆä½µå‰©é¤˜æ–‡å­—ä»¥åˆ©åµæ¸¬ä¾¿åˆ©å•†åº—
    merged_text = "\n".join(sum(data.values(), []))
    delivery = detect_delivery_method(merged_text)

    # è‹¥æœªåµæ¸¬åˆ°ä¾¿åˆ©å•†åº—ã€ä½†æœ‰åœ°å€ â†’ å¯„é€æ–¹å¼=ã€Œä¾¿åˆ©å¸¶ã€
    if not delivery and address:
        delivery = "ä¾¿åˆ©å¸¶"

    # å…¶ä»–æ–‡å­— â†’ æ¥­å‹™å‚™è¨»
    others = []
    for k, arr in data.items():
        for v in arr:
            if k != "_free_":
                others.append(f"{k}ï¼š{v}")
            else:
                others.append(v)
    biz_note = " / ".join([x for x in others if x.strip()])

    # é©—è­‰ï¼ˆè‹¥éä¾¿åˆ©å•†åº—éœ€åœ°å€ï¼‰
    errors = []
    if not name: errors.append("ç¼ºå°‘ã€å§“åã€‘")
    if not phone: errors.append("é›»è©±æ ¼å¼éŒ¯èª¤ï¼ˆéœ€ 09 é–‹é ­ 10 ç¢¼ï¼‰")
    if not book_raw: errors.append("ç¼ºå°‘ã€æ›¸åã€‘")
    if delivery not in ["7-11","å…¨å®¶","OK","èŠçˆ¾å¯Œ"] and not address:
        errors.append("ç¼ºå°‘ã€å¯„é€åœ°å€ã€‘ï¼ˆéè¶…å•†å¿…å¡«ï¼‰")

    return {
        "name": name,
        "phone": phone,
        "address": address,
        "book_raw": book_raw,
        "biz_note": biz_note,
        "delivery": delivery,
        "raw_text": raw_text
    }, errors

def _handle_new_order(event, text):
    try:
        profile = line_bot_api.get_profile(event.source.user_id)
        display_name = profile.display_name
    except Exception:
        display_name = "LINEä½¿ç”¨è€…"

    parsed, errs = _parse_new_order_text(text)
    if errs:
        msg = "âŒ å»ºæª”å¤±æ•—ï¼š\n- " + "\n- ".join(errs)
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
        return

    book_formal, kind, extra = resolve_book_name(parsed["book_raw"])
    if not book_formal:
        if kind == "ambiguous" and extra:
            msg = "â— æ›¸åæœ‰å¤šå€‹å¯èƒ½ï¼Œè«‹æ›´æ˜ç¢ºï¼š\n" + "ã€".join(extra[:10])
        else:
            msg = "âŒ æ‰¾ä¸åˆ°å°æ‡‰çš„æ›¸åï¼Œè«‹ç¢ºèªæˆ–è£œå……é—œéµå­—ã€‚"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
        return
    parsed["book_formal"] = book_formal

    ws = _ws(MAIN_SHEET_NAME)
    row, meta = _build_insert_row(ws, parsed, display_name)
    _insert_row_values_no_inherit(ws, row, index=2)  # ä¸Šæ–°ä¸‹èˆŠï¼ˆä¸ç¹¼æ‰¿æ ¼å¼ï¼‰

    resp = (
        "âœ… å·²æˆåŠŸå»ºæª”\n"
        f"ç´€éŒ„IDï¼š{meta['rid']}\n"
        f"å»ºå–®æ—¥æœŸï¼š{now_str_min()}\n"
        f"å§“åï¼š{parsed['name']}ï½œé›»è©±ï¼š{parsed['phone']}\n"
        f"åœ°å€ï¼š{row[_get_header_map(ws).get('å¯„é€åœ°å€',6)-1]}\n"
        f"æ›¸ç±ï¼š{book_formal}\n"
        f"ç‹€æ…‹ï¼šå¾…è™•ç†"
    )
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=resp))

# ============================================
# æŸ¥è©¢å¯„æ›¸ï¼ˆé è¨­ä¸é¡¯ç¤ºã€Œå·²åˆªé™¤ã€ï¼‰
# ============================================
def _handle_query(event, text):
    q = re.sub(r"^#(æŸ¥è©¢å¯„æ›¸|æŸ¥å¯„æ›¸)\s*", "", text.strip())

    ws = _ws(MAIN_SHEET_NAME)
    h = _get_header_map(ws)
    idxB = _col_idx(h, "å»ºå–®æ—¥æœŸ", 2)
    idxD = _col_idx(h, "å­¸å“¡å§“å", 4)
    idxE = _col_idx(h, "å­¸å“¡é›»è©±", 5)
    idxG = _col_idx(h, "æ›¸ç±åç¨±", 7)
    idxI = _col_idx(h, "å¯„é€æ–¹å¼", 9)
    idxJ = _col_idx(h, "å¯„å‡ºæ—¥æœŸ", 10)
    idxK = _col_idx(h, "è¨—é‹å–®è™Ÿ", 11)
    idxM = _col_idx(h, "å¯„é€ç‹€æ…‹", 13)

    rows = ws.get_all_values()[1:]
    since = datetime.now(TZ) - timedelta(days=QUERY_DAYS)

    phone_digits = re.sub(r"\D+","", q)
    is_phone = len(phone_digits) >= 7

    results = []
    for r in rows:
        try:
            st = (r[idxM-1] or "").strip()
            if st == "å·²åˆªé™¤":
                continue  # é è¨­ä¸é¡¯ç¤ºå·²åˆªé™¤
            dt_str = r[idxB-1].strip()
            dt = None
            if dt_str:
                try:
                    dt = datetime.strptime(dt_str[:16], "%Y-%m-%d %H:%M").replace(tzinfo=TZ)
                except Exception:
                    dt = None
            if dt and dt < since:
                continue

            if is_phone:
                cand = re.sub(r"\D+","", r[idxE-1])
                if len(cand) >= PHONE_SUFFIX_MATCH and phone_digits[-PHONE_SUFFIX_MATCH:] == cand[-PHONE_SUFFIX_MATCH:]:
                    results.append(r)
            else:
                if q and q in r[idxD-1]:
                    results.append(r)
        except Exception:
            continue

    if not results:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âŒ æŸ¥ç„¡è¿‘ 30 å¤©å…§çš„å¯„æ›¸ç´€éŒ„ï¼Œè«‹ç¢ºèªå§“åæˆ–é›»è©±æ˜¯å¦æ­£ç¢ºã€‚"))
        return

    results.sort(key=lambda r: r[idxB-1], reverse=True)
    results = results[:5]

    blocks = []
    for r in results:
        name = r[idxD-1]
        book = r[idxG-1]
        status = (r[idxM-1] or "").strip()
        outd = (r[idxJ-1] or "").strip()
        ship = (r[idxI-1] or "").strip()
        no = (r[idxK-1] or "").strip()

        if status == "å·²è¨—é‹":
            lines = [f"ğŸ“¦ {name} çš„ {book}"]
            if outd: lines.append(f"å·²æ–¼ {outd}")
            if ship: lines.append(f"ç”± {ship} å¯„å‡º")
            if no:   lines.append(f"è¨—é‹å–®è™Ÿï¼š{no}")
            blocks.append("\n".join(lines))
        else:
            blocks.append(f"ğŸ“¦ {name} çš„ {book} {status or 'å¾…è™•ç†'}")

    msg = "\n\n".join(blocks)
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))

# ============================================
# å–æ¶ˆå¯„æ›¸ï¼ˆè»Ÿåˆªé™¤ï¼›ç„¡åˆªé™¤ç·šï¼‰
# æŒ‡ä»¤ï¼š#å–æ¶ˆå¯„æ›¸  [å§“å/é›»è©± å¯åŒæ™‚]
# æ¬Šé™ï¼šå»ºå–®äººï¼ˆCæ¬„ï¼‰é ˆç­‰æ–¼æ“ä½œè€…çš„ LINE é¡¯ç¤ºåç¨±
# ç¢ºèªï¼šé¡¯ç¤ºæ‘˜è¦ï¼Œè¦æ±‚å›è¦† Y/N
# ============================================
_PENDING = {}  # user_id -> pending dict

def _extract_cancel_target(text: str):
    body = re.sub(r"^#å–æ¶ˆå¯„æ›¸\s*", "", text.strip())
    name, phone = None, None

    data = parse_kv_lines(body)
    for k in list(data.keys()):
        if any(x in k for x in ["å§“å","å­¸å“¡","æ”¶ä»¶äºº","åå­—","è²´å§“"]):
            name = "ã€".join(data.pop(k)); break
    for k in list(data.keys()):
        if "é›»è©±" in k:
            for v in data.pop(k):
                p = normalize_phone(v)
                if p: phone = p; break
            break

    if not name or not phone:
        tokens = re.split(r"\s+", body)
        for t in tokens:
            tt = t.strip()
            if not tt: continue
            p = normalize_phone(tt)
            if (not phone) and p: phone = p; continue
            if not name and not re.search(r"\d", tt): name = tt
    return (name, phone)

def _find_latest_order(ws, name, phone):
    h = _get_header_map(ws)
    idxA = _col_idx(h, "ç´€éŒ„ID", 1)
    idxB = _col_idx(h, "å»ºå–®æ—¥æœŸ", 2)
    idxC = _col_idx(h, "å»ºå–®äºº", 3)
    idxD = _col_idx(h, "å­¸å“¡å§“å", 4)
    idxE = _col_idx(h, "å­¸å“¡é›»è©±", 5)
    idxM = _col_idx(h, "å¯„é€ç‹€æ…‹", 13)

    all_vals = ws.get_all_values()
    rows = all_vals[1:]
    since = datetime.now(TZ) - timedelta(days=QUERY_DAYS)

    phone_suffix = None
    if phone:
        pd = re.sub(r"\D+","", phone)
        if len(pd) >= PHONE_SUFFIX_MATCH:
            phone_suffix = pd[-PHONE_SUFFIX_MATCH:]

    candidates = []
    for ridx, r in enumerate(rows, start=2):
        try:
            dt_str = (r[idxB-1] or "").strip()
            dt = None
            if dt_str:
                try:
                    dt = datetime.strptime(dt_str[:16], "%Y-%m-%d %H:%M").replace(tzinfo=TZ)
                except Exception:
                    dt = None
            if dt and dt < since: continue

            ok = True
            if name and name not in (r[idxD-1] or ""): ok = False
            if phone_suffix:
                cand = re.sub(r"\D+","", r[idxE-1] or "")
                if not (len(cand) >= PHONE_SUFFIX_MATCH and cand[-PHONE_SUFFIX_MATCH:] == phone_suffix):
                    ok = False
            if ok: candidates.append((ridx, r))
        except Exception:
            continue

    if not candidates: return (None, None)
    candidates.sort(key=lambda x: x[1][idxB-1], reverse=True)
    return candidates[0]

def _handle_cancel_request(event, text):
    try:
        profile = line_bot_api.get_profile(event.source.user_id)
        display_name = profile.display_name or "LINEä½¿ç”¨è€…"
    except Exception:
        display_name = "LINEä½¿ç”¨è€…"

    name, phone = _extract_cancel_target(text)
    ws = _ws(MAIN_SHEET_NAME)
    h = _get_header_map(ws)
    idxA = _col_idx(h, "ç´€éŒ„ID", 1)
    idxB = _col_idx(h, "å»ºå–®æ—¥æœŸ", 2)
    idxC = _col_idx(h, "å»ºå–®äºº", 3)
    idxD = _col_idx(h, "å­¸å“¡å§“å", 4)
    idxG = _col_idx(h, "æ›¸ç±åç¨±", 7)
    idxJ = _col_idx(h, "å¯„å‡ºæ—¥æœŸ", 10)
    idxK = _col_idx(h, "è¨—é‹å–®è™Ÿ", 11)
    idxL = _col_idx(h, "ç¶“æ‰‹äºº", 12)
    idxM = _col_idx(h, "å¯„é€ç‹€æ…‹", 13)
    idxH = _col_idx(h, "æ¥­å‹™å‚™è¨»", 8)

    row_i, r = _find_latest_order(ws, name, phone)
    if not row_i:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âŒ æ‰¾ä¸åˆ°ç´€éŒ„"))
        return

    creator = (r[idxC-1] or "").strip() or "LINEä½¿ç”¨è€…"
    if creator != display_name:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âŒ ä½ æ²’æœ‰åˆªé™¤æ¬Šé™ï¼ˆè«‹è¯ç¹«ç®¡ç†è€…ï¼‰"))
        return

    status = (r[idxM-1] or "").strip()
    outd = (r[idxJ-1] or "").strip()
    shipno = (r[idxK-1] or "").strip()
    if status == "å·²è¨—é‹":
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âŒ å·²è¨—é‹ï¼Œç„¡æ³•åˆªé™¤")); return
    if status == "å·²åˆªé™¤":
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="â— å·²æ˜¯å·²åˆªé™¤ç‹€æ…‹")); return
    if (shipno or outd) and status != "å·²è¨—é‹":
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="â— ç„¡æ³•è™•ç†ï¼Œè«‹ç§è¨Šå®¢æœã€‚")); return

    stu = r[idxD-1]; book = r[idxG-1]
    _PENDING[event.source.user_id] = {
        "type": "cancel_order",
        "sheet": MAIN_SHEET_NAME,
        "row_i": row_i,
        "rid": r[idxA-1],
        "stu": stu,
        "book": book,
        "status": status,
        "operator": display_name,
        "idx": {"H": idxH, "L": idxL, "M": idxM}
    }
    prompt = f"è«‹ç¢ºèªæ˜¯å¦åˆªé™¤ï¼š\nå­¸å“¡ï¼š{stu}\næ›¸åï¼š{book}\nç‹€æ…‹ï¼š{status or 'å¾…è™•ç†'}\n[Y/N]"
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=prompt))

def _handle_pending_answer(event, text):
    pend = _PENDING.get(event.source.user_id)
    if not pend: return False
    ans = text.strip().upper()
    if ans not in ("Y","N"): return False
    if ans == "N":
        _PENDING.pop(event.source.user_id, None)
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="å·²çµæŸå°è©±ã€‚"))
        return True

    ws = _ws(pend["sheet"])
    row_i = pend["row_i"]
    idxH = pend["idx"]["H"]
    idxL = pend["idx"]["L"]
    idxM = pend["idx"]["M"]

    try:
        curr_h = ws.cell(row_i, idxH).value or ""
    except Exception:
        curr_h = ""
    append_note = f"[å·²åˆªé™¤ {now_str_min()}]"
    new_h = (curr_h + " " + append_note).strip() if curr_h else append_note

    ws.update_cell(row_i, idxH, new_h)
    ws.update_cell(row_i, idxL, pend["operator"])
    ws.update_cell(row_i, idxM, "å·²åˆªé™¤")

    msg = f"âœ… å¯„æ›¸ä»»å‹™å·²åˆªé™¤ï¼š{pend['stu']} çš„ {pend['book']}"
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
    _PENDING.pop(event.source.user_id, None)
    return True

# ============================================
# åœ–ç‰‡ï¼ˆOCRï¼‰è™•ç†ï¼šå¯«å›å–®è™Ÿ/å‡ºè²¨æ—¥/ç¶“æ‰‹äºº/ç‹€æ…‹
# ============================================
def _download_line_image_bytes(message_id: str) -> bytes:
    content = line_bot_api.get_message_content(message_id)
    return b"".join(chunk for chunk in content.iter_content())

def _ocr_text_from_bytes(img_bytes: bytes) -> str:
    if not _vision_client:
        raise RuntimeError("Vision ç”¨æˆ¶ç«¯æœªåˆå§‹åŒ–ï¼ˆè«‹ç¢ºèª GOOGLE_SERVICE_ACCOUNT_JSON å·²è¨­å®šï¼Œä¸”å°ˆæ¡ˆå·²å•Ÿç”¨ Vision APIï¼‰ã€‚")
    image = vision.Image(content=img_bytes)
    resp = _vision_client.text_detection(image=image)
    if resp.error.message:
        raise RuntimeError(resp.error.message)
    text = resp.full_text_annotation.text if resp.full_text_annotation else ""
    return text or ""

def _pair_ids_with_numbers(text: str):
    if not text:
        return [], ["æœªè®€å–åˆ°æ–‡å­—"]
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    if LOG_OCR_RAW:
        app.logger.info(f"[OCR_RAW_OUTPUT] {repr(text[:1000])}")

    rids, nums = [], []
    for i, ln in enumerate(lines):
        for m in re.finditer(r"R\d{4}", ln):
            rids.append((m.group(), i))
        for m in re.finditer(r"\d{12}", ln):
            nums.append((m.group(), i))

    pairs, used_num, leftovers = [], set(), []
    for rid, li in rids:
        chosen, best_dist = None, 999
        for no, lj in nums:
            if (no, lj) in used_num:
                continue
            d = abs(lj - li)
            if d < best_dist:
                best_dist = d
                chosen = (no, lj)
        if chosen:
            pairs.append((rid, chosen[0]))
            used_num.add(chosen)
        else:
            leftovers.append(f"{rid}ï½œæœªæ‰¾åˆ° 12 ç¢¼å–®è™Ÿ")

    for no, lj in nums:
        if (no, lj) not in used_num:
            leftovers.append(f"æœªé…å°å–®è™Ÿï¼š{no}")

    return pairs, leftovers

def _write_ocr_results(pairs, event):
    if not pairs:
        return "â— æœªå¯«å…¥ä»»ä½•è³‡æ–™ï¼ˆæœªæ‰¾åˆ°é…å°ï¼‰"
    ws = _ws(MAIN_SHEET_NAME)
    h = _get_header_map(ws)
    idxA = _col_idx(h, "ç´€éŒ„ID", 1)
    idxJ = _col_idx(h, "å¯„å‡ºæ—¥æœŸ", 10)
    idxK = _col_idx(h, "è¨—é‹å–®è™Ÿ", 11)
    idxL = _col_idx(h, "ç¶“æ‰‹äºº", 12)
    idxM = _col_idx(h, "å¯„é€ç‹€æ…‹", 13)

    try:
        profile = line_bot_api.get_profile(event.source.user_id)
        uploader = profile.display_name or "LINEä½¿ç”¨è€…"
    except Exception:
        uploader = "LINEä½¿ç”¨è€…"

    all_vals = ws.get_all_values()
    rows = all_vals[1:]
    id2row = {}
    for ridx, r in enumerate(rows, start=2):
        try:
            rid = (r[idxA-1] or "").strip()
            if re.fullmatch(r"R\d{4}", rid):
                id2row[rid] = ridx
        except Exception:
            continue

    updated = []
    for rid, no in pairs:
        row_i = id2row.get(rid)
        if not row_i:
            continue
        ws.update_cell(row_i, idxK, f"'{no}")
        ws.update_cell(row_i, idxJ, today_str())
        ws.update_cell(row_i, idxL, uploader)
        ws.update_cell(row_i, idxM, "å·²è¨—é‹")
        updated.append((rid, no))

    if not updated:
        return "â— æœªå¯«å…¥ï¼ˆæ‰¾ä¸åˆ°å°æ‡‰çš„ç´€éŒ„IDï¼‰"

    lines = [f"{rid} â†’ {no}" for rid, no in updated]
    return "âœ… å·²æ›´æ–°ï¼š{} ç­†\n{}".format(len(updated), "\n".join(lines))

# ============================================
# LINE Webhook
# ============================================
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature", "")
    body = request.get_data(as_text=True)
    app.logger.info("Request body: " + body)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return "OK"

# æ–‡å­—è¨Šæ¯è™•ç†
@handler.add(MessageEvent, message=TextMessage)
def handle_text_message(event):
    text = (event.message.text or "").strip()

    # å…ˆè™•ç†å¾…ç¢ºèªçš„ Y/N
    if _handle_pending_answer(event, text):
        return

    if text.startswith("#å¯„æ›¸éœ€æ±‚") or text.startswith("#å¯„æ›¸"):
        _handle_new_order(event, text); return

    if text.startswith("#æŸ¥è©¢å¯„æ›¸") or text.startswith("#æŸ¥å¯„æ›¸"):
        _handle_query(event, text); return

    if text.startswith("#å–æ¶ˆå¯„æ›¸"):
        _handle_cancel_request(event, text); return

    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text="è«‹ä½¿ç”¨ï¼š\n#å¯„æ›¸ï¼ˆå»ºç«‹å¯„æ›¸ä»»å‹™ï¼‰\n#æŸ¥å¯„æ›¸ï¼ˆå§“åæˆ–é›»è©±ï¼‰\n#å–æ¶ˆå¯„æ›¸ï¼ˆå§“åæˆ–é›»è©±ï¼‰")
    )

# åœ–ç‰‡è¨Šæ¯è™•ç†ï¼ˆOCRï¼‰
@handler.add(MessageEvent, message=ImageMessage)
def handle_image_message(event):
    try:
        app.logger.info(f"[IMG] æ”¶åˆ°åœ–ç‰‡ user_id={getattr(event.source,'user_id','unknown')} msg_id={event.message.id}")
        img_bytes = _download_line_image_bytes(event.message.id)
        if not _vision_client:
            msg = "âŒ OCR è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼šVision ç”¨æˆ¶ç«¯æœªåˆå§‹åŒ–ï¼ˆè«‹ç¢ºèª GOOGLE_SERVICE_ACCOUNT_JSON å·²è¨­å®šï¼Œä¸”å°ˆæ¡ˆå·²å•Ÿç”¨ Vision APIï¼‰ã€‚"
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg)); return

        text = _ocr_text_from_bytes(img_bytes)
        if LOG_OCR_RAW:
            app.logger.info(f"[OCR_TEXT]\n{text}")

        pairs, leftovers = _pair_ids_with_numbers(text)
        resp = _write_ocr_results(pairs, event)
        if leftovers:
            resp += "\n\nâ—ä»¥ä¸‹é …ç›®éœ€äººå·¥æª¢æ ¸ï¼š\n" + "\n".join(leftovers[:10])

        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=resp))
    except Exception as e:
        code = datetime.now(TZ).strftime("%Y%m%d%H%M%S")
        app.logger.exception("[OCR_ERROR]")
        msg = f"âŒ OCR éŒ¯èª¤ï¼ˆä»£ç¢¼ {code}ï¼‰ï¼š{e}"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))

# å¥åº·æª¢æŸ¥
@app.route("/", methods=["GET"])
def index():
    try:
        names = [ws.title for ws in ss.worksheets()]
        return "OK / Worksheets: " + ", ".join(names)
    except Exception as e:
        return f"OK / (Sheets not loaded) {e}"

# æœ¬åœ°åŸ·è¡Œï¼ˆRailway ç”¨ gunicorn å•Ÿå‹•ï¼‰
if __name__ == "__main__":
    port = int(os.getenv("PORT", "8080"))
    app.run(host="0.0.0.0", port=port)

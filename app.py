# app.py - å„ªåŒ–ç‰ˆ
# ============================================
# ä¿®å¾©é …ç›®ï¼š
# S1: Vision OCR æ­£ç¢ºåˆå§‹åŒ–
# S2: ç§»é™¤é‡è¤‡ç¨‹å¼ç¢¼
# S3: Sheets é€£ç·šéŒ¯èª¤è™•ç†
# H1: å¤šä½¿ç”¨è€…éš”é›¢ï¼ˆuser_id ä½œç‚º keyï¼‰
# H2: æ‰€æœ‰ Sheets æ“ä½œåŠ å…¥éŒ¯èª¤è™•ç†
# H3: ç™½åå–®å³æ™‚åˆ·æ–°æ©Ÿåˆ¶
# M1: å„ªåŒ– Sheets è®€å–æ•ˆèƒ½
# M2: çµ±ä¸€å‡½å¼å‘½å
# M3: å¢åŠ é—œéµæ“ä½œæ—¥èªŒ
# æ–°åŠŸèƒ½ï¼š#æŸ¥æ›¸åï¼ˆåˆ†é¡æŸ¥è©¢ï¼‰+ å¼•å°ä¿®æ­£æµç¨‹
# ============================================

import os
import re
import io
import json
import difflib
import logging
import time
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from typing import Optional, Dict, List, Tuple, Any

from flask import Flask, request, abort
import gspread
from google.oauth2.service_account import Credentials

from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (
    MessageEvent, TextMessage, ImageMessage,
    TextSendMessage,
)

# ====== Vision OCR åˆå§‹åŒ–ï¼ˆä¿®å¾© S1ï¼‰======
_HAS_VISION = False
_vision_client = None

def _init_vision_client():
    """æ­£ç¢ºåˆå§‹åŒ– Vision API å®¢æˆ¶ç«¯"""
    global _vision_client, _HAS_VISION
    try:
        from google.cloud import vision
        from google.oauth2 import service_account as gcp_service_account
        
        json_path = "service_account.json"
        if os.path.exists(json_path):
            creds = gcp_service_account.Credentials.from_service_account_file(json_path)
            _vision_client = vision.ImageAnnotatorClient(credentials=creds)
            _HAS_VISION = True
            return
        
        sa_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON_NEW", "")
        if sa_json:
            info = json.loads(sa_json)
            creds = gcp_service_account.Credentials.from_service_account_info(info)
            _vision_client = vision.ImageAnnotatorClient(credentials=creds)
            _HAS_VISION = True
    except Exception as e:
        _HAS_VISION = False
        _vision_client = None
        print(f"[VISION] åˆå§‹åŒ–å¤±æ•—: {e}")

# å•Ÿå‹•æ™‚åˆå§‹åŒ– Vision
_init_vision_client()
# ==================================

app = Flask(__name__)
app.logger.setLevel(logging.INFO)

# ---- ç’°å¢ƒè®Šæ•¸ ----
SHEET_ID = os.getenv("SHEET_ID", "").strip()

MAIN_SHEET_NAME = os.getenv("MAIN_SHEET_NAME", "å¯„æ›¸ä»»å‹™")
BOOK_MASTER_SHEET_NAME = os.getenv("BOOK_MASTER_SHEET_NAME", "æ›¸ç›®ä¸»æª”")
ZIPREF_SHEET_NAME = os.getenv("ZIPREF_SHEET_NAME", "éƒµéå€è™Ÿåƒç…§è¡¨")
STOCK_IN_SHEET_NAME = os.getenv("STOCK_IN_SHEET_NAME", "å…¥åº«æ˜ç´°")
HISTORY_SHEET_NAME = os.getenv("HISTORY_SHEET_NAME", "æ­·å²ç´€éŒ„")

# === ç™½åå–®è¨­å®š ===
WHITELIST_SHEET_NAME = os.getenv("WHITELIST_SHEET_NAME", "ç™½åå–®")
CANDIDATE_SHEET_NAME = os.getenv("CANDIDATE_SHEET_NAME", "å€™é¸åå–®")
WHITELIST_MODE = os.getenv("WHITELIST_MODE", "enforce").strip().lower()
ADMIN_USER_IDS = {x.strip() for x in os.getenv("ADMIN_USER_IDS", "").split(",") if x.strip()}
_WHITELIST_CACHE = {"ts": 0.0, "set": set()}
_WHITELIST_TTL = 300

# === æ–°å¢å¸¸æ•¸å®šç¾©ï¼ˆä¿®å¾© L1ï¼‰===
FUZZY_THRESHOLD = float(os.getenv("FUZZY_THRESHOLD", "0.7"))
QUERY_DAYS = int(os.getenv("QUERY_DAYS", "30"))
PHONE_SUFFIX_MATCH = int(os.getenv("PHONE_SUFFIX_MATCH", "9"))
WRITE_ZIP_TO_ADDRESS = os.getenv("WRITE_ZIP_TO_ADDRESS", "true").lower() == "true"
LOG_OCR_RAW = os.getenv("LOG_OCR_RAW", "true").lower() == "true"
OCR_SESSION_TTL_MIN = int(os.getenv("OCR_SESSION_TTL_MIN", "10"))
MAX_BOOK_SUGGESTIONS = 3  # æœ€å¤šå»ºè­°æ›¸ç±æ•¸é‡
MAX_LEFTOVER_ITEMS = 10   # OCR æœªé…å°é …ç›®æœ€å¤šé¡¯ç¤ºæ•¸é‡
INSERT_AT_TOP = True  # å›ºå®šåœ¨ç¬¬äºŒåˆ—æ’å…¥æ–°è³‡æ–™

LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET", "")
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "")

if not LINE_CHANNEL_SECRET or not LINE_CHANNEL_ACCESS_TOKEN:
    raise RuntimeError("Missing LINE credentials.")

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

TZ = ZoneInfo("Asia/Taipei")

# ============================================
# å…¨åŸŸç‹€æ…‹ç®¡ç†ï¼ˆä¿®å¾© H1ï¼šä½¿ç”¨ user_id éš”é›¢ï¼‰
# ============================================
_PENDING: Dict[str, Dict[str, Any]] = {}  # user_id -> pending_data
_OCR_SESSIONS: Dict[str, float] = {}  # user_id -> expire_timestamp

# ============================================
# Google Sheets é€£ç·šï¼ˆä¿®å¾© S3ï¼šåŠ å…¥éŒ¯èª¤è™•ç†ï¼‰
# ============================================
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]

def _build_gspread_client():
    """å»ºç«‹ gspread å®¢æˆ¶ç«¯"""
    json_path = "service_account.json"
    if os.path.exists(json_path):
        creds = Credentials.from_service_account_file(json_path, scopes=SCOPES)
        return gspread.authorize(creds)
    
    sa_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON_NEW", "")
    if not sa_json:
        raise RuntimeError("Missing service account credentials.")
    
    creds = Credentials.from_service_account_info(json.loads(sa_json), scopes=SCOPES)
    return gspread.authorize(creds)

def _safe_open_spreadsheet(sheet_id: str):
    """å®‰å…¨é–‹å•Ÿè©¦ç®—è¡¨ï¼ˆä¿®å¾© S3ï¼‰"""
    try:
        gc = _build_gspread_client()
        return gc.open_by_key(sheet_id)
    except Exception as e:
        app.logger.error(f"[SHEETS] ç„¡æ³•é–‹å•Ÿè©¦ç®—è¡¨ {sheet_id}: {e}")
        raise RuntimeError(f"ç„¡æ³•é€£ç·šè‡³ Google Sheets: {e}")

# åˆå§‹åŒ–è©¦ç®—è¡¨
try:
    ss = _safe_open_spreadsheet(SHEET_ID)
    app.logger.info(f"[SHEETS] æˆåŠŸé€£ç·šè‡³è©¦ç®—è¡¨")
except Exception as e:
    app.logger.error(f"[SHEETS] å•Ÿå‹•å¤±æ•—: {e}")
    ss = None  # å…è¨±æœå‹™å•Ÿå‹•ï¼Œä½†æœƒåœ¨æ“ä½œæ™‚å ±éŒ¯

def _ws(name: str):
    """å–å¾—å·¥ä½œè¡¨ï¼ˆä¿®å¾© H2ï¼šåŠ å…¥éŒ¯èª¤è™•ç†ï¼‰"""
    try:
        return ss.worksheet(name)
    except gspread.WorksheetNotFound:
        app.logger.error(f"[SHEETS] å·¥ä½œè¡¨ä¸å­˜åœ¨: {name}")
        raise ValueError(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨ï¼š{name}")
    except Exception as e:
        app.logger.error(f"[SHEETS] å–å¾—å·¥ä½œè¡¨å¤±æ•— {name}: {e}")
        raise

def _get_or_create_ws(name: str, headers: list):
    """å–å¾—æˆ–å»ºç«‹å·¥ä½œè¡¨ï¼ˆä¿®å¾© H2ï¼‰"""
    try:
        ws = ss.worksheet(name)
        return ws
    except gspread.WorksheetNotFound:
        try:
            ws = ss.add_worksheet(title=name, rows=200, cols=max(10, len(headers)))
            if headers:
                ws.update(f"A1:{chr(64+len(headers))}1", [headers])
            app.logger.info(f"[SHEETS] å·²å»ºç«‹å·¥ä½œè¡¨: {name}")
            return ws
        except Exception as e:
            app.logger.error(f"[SHEETS] å»ºç«‹å·¥ä½œè¡¨å¤±æ•— {name}: {e}")
            raise
    except Exception as e:
        app.logger.error(f"[SHEETS] å–å¾—å·¥ä½œè¡¨å¤±æ•— {name}: {e}")
        raise

def _get_header_map(ws):
    """å–å¾—è¡¨é ­å°æ‡‰ï¼ˆä¿®å¾© H2ï¼‰"""
    try:
        header = ws.row_values(1)
        hmap = {}
        for idx, title in enumerate(header, start=1):
            t = str(title).strip()
            if t:
                hmap[t] = idx
        return hmap
    except Exception as e:
        app.logger.error(f"[SHEETS] å–å¾—è¡¨é ­å¤±æ•—: {e}")
        return {}

def _col_idx(hmap, key, default_idx):
    """å–å¾—æ¬„ä½ç´¢å¼•"""
    return hmap.get(key, default_idx)

def _safe_update_cell(ws, row: int, col: int, value: Any):
    """å®‰å…¨æ›´æ–°å„²å­˜æ ¼ï¼ˆä¿®å¾© H2 + M3ï¼‰"""
    try:
        ws.update_cell(row, col, value)
        app.logger.info(f"[SHEETS] æ›´æ–° {ws.title} R{row}C{col} = {value}")
    except Exception as e:
        app.logger.error(f"[SHEETS] æ›´æ–°å¤±æ•— R{row}C{col}: {e}")
        raise

def _safe_append_row(ws, row_data: list):
    """å®‰å…¨æ–°å¢åˆ—ï¼ˆå›ºå®šæ’å…¥ç¬¬äºŒåˆ—ï¼Œä¸ç¹¼æ‰¿æ ¼å¼ï¼‰"""
    try:
        if INSERT_AT_TOP:
            # åœ¨ç¬¬ 2 åˆ—ï¼ˆè¡¨é ­ä¸‹æ–¹ï¼‰æ’å…¥æ–°è³‡æ–™
            # inheritFromBefore=False ç¢ºä¿ä¸ç¹¼æ‰¿ä¸Šæ–¹æ ¼å¼
            ws.insert_row(row_data, index=2, value_input_option="USER_ENTERED", inherit_from_before=False)
            app.logger.info(f"[SHEETS] æ’å…¥åˆ—è‡³ {ws.title} ç¬¬2åˆ—: {row_data[:3]}...")
        else:
            # åœ¨æœ€ä¸‹é¢æ–°å¢ï¼ˆä¿ç•™åŸé‚è¼¯ï¼Œä½†ç›®å‰ä¸ä½¿ç”¨ï¼‰
            ws.append_row(row_data, value_input_option="USER_ENTERED")
            app.logger.info(f"[SHEETS] æ–°å¢åˆ—è‡³ {ws.title}: {row_data[:3]}...")
    except Exception as e:
        app.logger.error(f"[SHEETS] æ–°å¢åˆ—å¤±æ•—: {e}")
        raise

def _safe_append_rows(ws, rows_data: list):
    """å®‰å…¨æ‰¹æ¬¡æ–°å¢åˆ—ï¼ˆä¿®å¾© H2 + M3ï¼‰"""
    try:
        ws.append_rows(rows_data, value_input_option="USER_ENTERED")
        app.logger.info(f"[SHEETS] æ‰¹æ¬¡æ–°å¢ {len(rows_data)} åˆ—è‡³ {ws.title}")
    except Exception as e:
        app.logger.error(f"[SHEETS] æ‰¹æ¬¡æ–°å¢å¤±æ•—: {e}")
        raise

# ============================================
# ç™½åå–®åŠŸèƒ½ï¼ˆä¿®å¾© H3ï¼šå³æ™‚åˆ·æ–°ï¼‰
# ============================================
def _truthy(v) -> bool:
    """åˆ¤æ–·å€¼æ˜¯å¦ç‚ºçœŸ"""
    s = str(v).strip().lower()
    return s in ("1", "true", "yes", "y", "t", "å•Ÿç”¨", "æ˜¯", "enabled", "on")

def _load_whitelist(force: bool = False) -> set:
    """è¼‰å…¥ç™½åå–®ï¼ˆä¿®å¾© H3ï¼šæ”¯æ´å¼·åˆ¶åˆ·æ–°ï¼‰"""
    now = time.time()
    if (not force) and _WHITELIST_CACHE["set"] and (now - _WHITELIST_CACHE["ts"] < _WHITELIST_TTL):
        return _WHITELIST_CACHE["set"]
    
    try:
        ws = _get_or_create_ws(WHITELIST_SHEET_NAME, ["user_id", "name", "enabled"])
        rows = ws.get_all_records()
        enabled = {
            str(r.get("user_id", "")).strip() 
            for r in rows 
            if str(r.get("user_id", "")).strip() and _truthy(r.get("enabled", "1"))
        }
        _WHITELIST_CACHE["set"] = enabled
        _WHITELIST_CACHE["ts"] = now
        app.logger.info(f"[WHITELIST] å·²è¼‰å…¥ {len(enabled)} å€‹æˆæ¬Šä½¿ç”¨è€…")
        return enabled
    except Exception as e:
        app.logger.error(f"[WHITELIST] è¼‰å…¥å¤±æ•—: {e}")
        return _WHITELIST_CACHE["set"]  # å›å‚³èˆŠå¿«å–

def _log_candidate(user_id: str, name: str):
    """è¨˜éŒ„å€™é¸åå–®ï¼ˆä¿®å¾© H2ï¼‰"""
    try:
        ws = _get_or_create_ws(CANDIDATE_SHEET_NAME, ["user_id", "name", "first_seen", "last_seen"])
        all_vals = ws.get_all_values()
        h = _get_header_map(ws)
        idx_uid = _col_idx(h, "user_id", 1)
        idx_name = _col_idx(h, "name", 2)
        idx_first = _col_idx(h, "first_seen", 3)
        idx_last = _col_idx(h, "last_seen", 4)

        exists_row = None
        for i, r in enumerate(all_vals[1:], start=2):
            if (len(r) >= idx_uid) and r[idx_uid - 1] == user_id:
                exists_row = i
                break

        now_s = datetime.now(TZ).strftime("%Y-%m-%d %H:%M")
        if exists_row:
            if name:
                _safe_update_cell(ws, exists_row, idx_name, name)
            _safe_update_cell(ws, exists_row, idx_last, now_s)
        else:
            _safe_append_row(ws, [user_id, name, now_s, now_s])
    except Exception as e:
        app.logger.warning(f"[CANDIDATE] è¨˜éŒ„å¤±æ•—: {e}")

def _ensure_authorized(event, scope: str = "*") -> bool:
    """é©—è­‰æˆæ¬Šï¼ˆä¿®å¾© M3ï¼šå¢åŠ æ—¥èªŒï¼‰"""
    try:
        uid = getattr(event.source, "user_id", "")
        profile = line_bot_api.get_profile(uid)
        display_name = profile.display_name or "LINEä½¿ç”¨è€…"
    except Exception:
        uid = getattr(event.source, "user_id", "")
        display_name = "LINEä½¿ç”¨è€…"

    if uid:
        _log_candidate(uid, display_name)

    if uid in ADMIN_USER_IDS:
        app.logger.info(f"[AUTH] ç®¡ç†å“¡é€šé: {uid}")
        return True
    
    if WHITELIST_MODE in ("off", "log"):
        app.logger.info(f"[AUTH] ç™½åå–®æ¨¡å¼ {WHITELIST_MODE}ï¼Œå…è¨±: {uid}")
        return True

    allowed = _load_whitelist()
    if uid in allowed:
        app.logger.info(f"[AUTH] ç™½åå–®é€šé: {uid}")
        return True

    app.logger.warning(f"[AUTH] æœªæˆæ¬Š: {uid}")
    if scope == "text":
        msg = f"âŒ å°šæœªæˆæ¬Šä½¿ç”¨ã€‚\nè«‹å°‡æ­¤ ID æä¾›çµ¦ç®¡ç†å“¡é–‹é€šï¼š\n{uid}\n\nï¼ˆæç¤ºï¼šå‚³ã€Œ#æˆ‘çš„IDã€ä¹Ÿèƒ½å–å¾—é€™ä¸² IDï¼‰"
        try:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
        except Exception:
            pass
    return False

# ============================================
# å·¥å…·å‡½å¼
# ============================================
def now_str_min():
    """ç›®å‰æ™‚é–“å­—ä¸²ï¼ˆåˆ†é˜ï¼‰"""
    return datetime.now(TZ).strftime("%Y-%m-%d %H:%M")

def today_str():
    """ä»Šæ—¥æ—¥æœŸå­—ä¸²"""
    return datetime.now(TZ).strftime("%Y-%m-%d")

def normalize_phone(s: str) -> Optional[str]:
    """æ­£è¦åŒ–é›»è©±è™Ÿç¢¼ï¼ˆæ”¾å¯¬è¦å‰‡ï¼š09 é–‹é ­ + 10 ä½æ•¸ï¼‰"""
    digits = re.sub(r"\D+", "", s or "")
    # æª¢æŸ¥ï¼šç¬¬ä¸€ç¢¼æ˜¯ 0ï¼Œç¬¬äºŒç¢¼æ˜¯ 9ï¼Œç¸½å…± 10 ä½æ•¸
    if len(digits) == 10 and digits[0] == "0" and digits[1] == "9":
        return digits
    return None

def parse_kv_lines(text: str) -> Dict[str, str]:
    """è§£æ key:value æ ¼å¼æ–‡å­—ï¼Œæ”¯æ´å¤šç¨®æ¬„ä½åç¨±"""
    data = {}
    for line in text.strip().split("\n"):
        line = line.strip()
        if not line:
            continue
        if "ï¼š" in line:
            k, v = line.split("ï¼š", 1)
            data[k.strip()] = v.strip()
        elif ":" in line:
            k, v = line.split(":", 1)
            data[k.strip()] = v.strip()
    
    # æ¬„ä½åç¨±æ­£è¦åŒ–ï¼ˆæ”¯æ´å¤šç¨®å¯«æ³•ï¼‰
    normalized = {}
    
    # å§“åæ¬„ä½
    for key in ["å§“å", "å­¸å“¡å§“å", "name", "Name"]:
        if key in data:
            normalized["å§“å"] = data[key]
            break
    
    # é›»è©±æ¬„ä½
    for key in ["é›»è©±", "å­¸å“¡é›»è©±", "phone", "Phone", "æ‰‹æ©Ÿ"]:
        if key in data:
            normalized["é›»è©±"] = data[key]
            break
    
    # åœ°å€æ¬„ä½
    for key in ["å¯„é€åœ°å€", "åœ°å€", "address", "Address"]:
        if key in data:
            normalized["å¯„é€åœ°å€"] = data[key]
            break
    
    # æ›¸ç±æ¬„ä½
    for key in ["æ›¸ç±åç¨±", "æ›¸å", "book", "Book", "æ›¸ç±"]:
        if key in data:
            normalized["æ›¸ç±åç¨±"] = data[key]
            break
    
    # å‚™è¨»æ¬„ä½
    for key in ["æ¥­å‹™å‚™è¨»", "å‚™è¨»", "note", "Note"]:
        if key in data:
            normalized["æ¥­å‹™å‚™è¨»"] = data[key]
            break
    
    return normalized

# ============================================
# æ›¸ç›®ä¸»æª”å¿«å–ï¼ˆä¿®å¾© M1ï¼šå„ªåŒ–è®€å–æ•ˆèƒ½ï¼‰
# ============================================
_BOOK_CACHE = {"ts": 0.0, "books": []}
_BOOK_CACHE_TTL = 600  # 10 åˆ†é˜

def _load_books(force: bool = False) -> List[Dict[str, Any]]:
    """è¼‰å…¥æ›¸ç›®ä¸»æª”ï¼ˆå«å¿«å–æ©Ÿåˆ¶ï¼Œä¿®å¾© M1ï¼‰"""
    now = time.time()
    if (not force) and _BOOK_CACHE["books"] and (now - _BOOK_CACHE["ts"] < _BOOK_CACHE_TTL):
        return _BOOK_CACHE["books"]
    
    try:
        ws = _ws(BOOK_MASTER_SHEET_NAME)
        rows = ws.get_all_records()
        books = []
        for r in rows:
            if str(r.get("æ˜¯å¦å•Ÿç”¨", "")).strip() == "ä½¿ç”¨ä¸­":
                name = str(r.get("æ›¸ç±åç¨±", "")).strip()
                lang = str(r.get("èªåˆ¥", "")).strip()
                fuzzy = str(r.get("æ¨¡ç³Šæ¯”å°æ›¸å", "")).strip()
                stock = r.get("ç¾æœ‰åº«å­˜", 0)
                if name:
                    books.append({
                        "name": name,
                        "lang": lang,
                        "fuzzy": fuzzy,
                        "stock": stock
                    })
        _BOOK_CACHE["books"] = books
        _BOOK_CACHE["ts"] = now
        app.logger.info(f"[BOOK] å·²è¼‰å…¥ {len(books)} æœ¬æ›¸ç±")
        return books
    except Exception as e:
        app.logger.error(f"[BOOK] è¼‰å…¥å¤±æ•—: {e}")
        return _BOOK_CACHE["books"]  # å›å‚³èˆŠå¿«å–

def _search_books_by_keyword(keyword: str) -> List[Dict[str, Any]]:
    """æ ¹æ“šé—œéµå­—æœå°‹æ›¸ç±ï¼ˆæ–°åŠŸèƒ½ï¼‰"""
    books = _load_books()
    keyword_lower = keyword.lower()
    results = []
    
    for book in books:
        # æœå°‹æ›¸åã€èªåˆ¥ã€æ¨¡ç³Šæ¯”å°æ¬„ä½
        search_text = f"{book['name']} {book['lang']} {book['fuzzy']}".lower()
        if keyword_lower in search_text:
            results.append(book)
    
    app.logger.info(f"[BOOK] æœå°‹ã€Œ{keyword}ã€æ‰¾åˆ° {len(results)} æœ¬")
    return results

def _find_book_exact(name: str) -> Optional[str]:
    """ç²¾ç¢ºæŸ¥æ‰¾æ›¸å"""
    books = _load_books()
    name_lower = name.lower().strip()
    
    # 1. ç²¾ç¢ºæ¯”å°æ›¸å
    for book in books:
        if book["name"].lower() == name_lower:
            return book["name"]
    
    # 2. æ¨¡ç³Šæ¯”å°æ¬„ä½
    for book in books:
        fuzzy_names = [x.strip().lower() for x in book["fuzzy"].split() if x.strip()]
        if name_lower in fuzzy_names:
            return book["name"]
    
    return None

def _suggest_books(wrong_name: str, max_results: int = MAX_BOOK_SUGGESTIONS) -> List[str]:
    """æ ¹æ“šéŒ¯èª¤æ›¸åå»ºè­°é¸é …ï¼ˆå„ªå…ˆé—œéµå­—æœå°‹ï¼‰"""
    books = _load_books()
    wrong_lower = wrong_name.lower().strip()
    
    # ç­–ç•¥ 1ï¼šé—œéµå­—æœå°‹ï¼ˆæœå°‹æ›¸åå’Œæ¨¡ç³Šæ¬„ä½ï¼‰
    keyword_matches = []
    for book in books:
        search_text = f"{book['name']} {book['fuzzy']}".lower()
        if wrong_lower in search_text:
            keyword_matches.append(book["name"])
    
    if keyword_matches:
        app.logger.info(f"[BOOK] é—œéµå­—ã€Œ{wrong_name}ã€æ‰¾åˆ° {len(keyword_matches)} æœ¬æ›¸")
        return keyword_matches[:max_results]
    
    # ç­–ç•¥ 2ï¼šæ¨¡ç³Šæ¯”å°æ¬„ä½ç²¾ç¢ºåŒ¹é…
    for book in books:
        fuzzy_names = [x.strip().lower() for x in book["fuzzy"].split() if x.strip()]
        if wrong_lower in fuzzy_names:
            app.logger.info(f"[BOOK] æ¨¡ç³Šæ¬„ä½ç²¾ç¢ºåŒ¹é…ã€Œ{wrong_name}ã€â†’ {book['name']}")
            return [book["name"]]
    
    # ç­–ç•¥ 3ï¼šç›¸ä¼¼åº¦æ¯”å°ï¼ˆdifflibï¼‰
    candidates = []
    for book in books:
        # æ¯”å°æ›¸å
        ratio = difflib.SequenceMatcher(None, wrong_lower, book["name"].lower()).ratio()
        candidates.append((ratio, book["name"]))
        
        # æ¯”å°æ¨¡ç³Šæ¬„ä½
        for fuzzy in book["fuzzy"].split():
            if fuzzy.strip():
                ratio2 = difflib.SequenceMatcher(None, wrong_lower, fuzzy.strip().lower()).ratio()
                candidates.append((ratio2, book["name"]))
    
    # æ’åºä¸¦å»é‡
    candidates = sorted(set(candidates), key=lambda x: x[0], reverse=True)
    results = [name for score, name in candidates if score >= FUZZY_THRESHOLD]
    
    # å»é‡ä¸¦é™åˆ¶æ•¸é‡
    seen = set()
    unique_results = []
    for name in results:
        if name not in seen:
            seen.add(name)
            unique_results.append(name)
            if len(unique_results) >= max_results:
                break
    
    if unique_results:
        app.logger.info(f"[BOOK] ç›¸ä¼¼åº¦åŒ¹é…ã€Œ{wrong_name}ã€æ‰¾åˆ° {len(unique_results)} æœ¬æ›¸")
    else:
        app.logger.info(f"[BOOK] æ‰¾ä¸åˆ°ã€Œ{wrong_name}ã€çš„å»ºè­°æ›¸ç±")
    
    return unique_results

# ============================================
# éƒµéå€è™ŸæŸ¥è©¢ï¼ˆä¿®å¾© H2ï¼‰
# ============================================
def _normalize_address_for_compare(text: str) -> str:
    """æ­£è¦åŒ–åœ°å€ç”¨æ–¼æ¯”å°ï¼ˆè™•ç†å°/è‡ºå·®ç•°ï¼‰"""
    # çµ±ä¸€å°‡ã€Œè‡ºã€è½‰æ›ç‚ºã€Œå°ã€é€²è¡Œæ¯”å°
    return text.replace("è‡º", "å°").replace("å°", "å°")

def _find_zip_code(address: str) -> Optional[str]:
    """æŸ¥è©¢éƒµéå€è™Ÿï¼ˆæ”¯æ´ç¸£å¸‚+å€åŸŸåŒ¹é…ï¼Œæœ€é•·åŒ¹é…å„ªå…ˆï¼‰"""
    try:
        ws = _ws(ZIPREF_SHEET_NAME)
        rows = ws.get_all_records()
        
        # æ­£è¦åŒ–åœ°å€
        address_normalized = _normalize_address_for_compare(address)
        
        # æ”¶é›†æ‰€æœ‰åŒ¹é…çš„å€åŸŸï¼Œä¸¦æŒ‰é•·åº¦æ’åºï¼ˆæœ€é•·å„ªå…ˆï¼‰
        matches = []
        for row in rows:
            # æ”¯æ´å…©ç¨®æ ¼å¼ï¼š
            # æ ¼å¼1: åªæœ‰ã€Œå€åŸŸã€æ¬„ä½ï¼ˆä¾‹ï¼šå°å—å¸‚åŒ—å€ï¼‰
            # æ ¼å¼2: åˆ†åˆ¥æœ‰ã€Œç¸£å¸‚ã€å’Œã€Œå€åŸŸã€æ¬„ä½
            
            city = str(row.get("ç¸£å¸‚", "")).strip()
            district = str(row.get("å€åŸŸ", "")).strip()
            zip_code = str(row.get("éƒµéå€è™Ÿ", "")).strip()
            
            if not zip_code:
                continue
            
            # å»ºæ§‹å®Œæ•´å€åŸŸåç¨±
            if city and district:
                # æ ¼å¼2: ç¸£å¸‚ + å€åŸŸ
                full_district = f"{city}{district}"
            elif district:
                # æ ¼å¼1: åªæœ‰å€åŸŸ
                full_district = district
            else:
                continue
            
            # æ­£è¦åŒ–ä¸¦æ¯”å°
            full_district_normalized = _normalize_address_for_compare(full_district)
            
            if full_district_normalized in address_normalized:
                matches.append((len(full_district_normalized), zip_code, full_district))
        
        if matches:
            # æŒ‰åŒ¹é…é•·åº¦é™åºæ’åºï¼Œå–æœ€é•·çš„
            matches.sort(key=lambda x: x[0], reverse=True)
            best_match = matches[0]
            app.logger.info(f"[ZIP] æ‰¾åˆ°éƒµéå€è™Ÿ {best_match[1]} for {best_match[2]} (åŸåœ°å€: {address})")
            return best_match[1]
        
        app.logger.warning(f"[ZIP] æ‰¾ä¸åˆ°éƒµéå€è™Ÿ: {address}")
        return None
    except Exception as e:
        app.logger.error(f"[ZIP] æŸ¥è©¢å¤±æ•—: {e}")
        return None

# ============================================
# OCR æœƒè©±ç®¡ç†
# ============================================
def _start_ocr_session(user_id: str):
    """é–‹å•Ÿ OCR æœƒè©±"""
    expire = time.time() + (OCR_SESSION_TTL_MIN * 60)
    _OCR_SESSIONS[user_id] = expire
    app.logger.info(f"[OCR] é–‹å•Ÿæœƒè©±: {user_id}")

def _has_ocr_session(user_id: str) -> bool:
    """æª¢æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ OCR æœƒè©±"""
    if user_id not in _OCR_SESSIONS:
        return False
    if time.time() > _OCR_SESSIONS[user_id]:
        _OCR_SESSIONS.pop(user_id, None)
        return False
    return True

def _clear_ocr_session(user_id: str):
    """æ¸…é™¤ OCR æœƒè©±"""
    _OCR_SESSIONS.pop(user_id, None)
    app.logger.info(f"[OCR] é—œé–‰æœƒè©±: {user_id}")

def _download_line_image_bytes(message_id: str) -> bytes:
    """ä¸‹è¼‰ LINE åœ–ç‰‡"""
    try:
        content = line_bot_api.get_message_content(message_id)
        return b"".join(content.iter_content())
    except Exception as e:
        app.logger.error(f"[OCR] ä¸‹è¼‰åœ–ç‰‡å¤±æ•—: {e}")
        raise

def _ocr_text_from_bytes(img_bytes: bytes) -> str:
    """å¾åœ–ç‰‡æå–æ–‡å­—ï¼ˆä¿®å¾© S1ï¼‰"""
    if not _vision_client:
        raise RuntimeError("Vision API æœªåˆå§‹åŒ–")
    
    try:
        from google.cloud import vision
        image = vision.Image(content=img_bytes)
        response = _vision_client.text_detection(image=image)
        
        if response.error.message:
            raise RuntimeError(f"Vision API éŒ¯èª¤: {response.error.message}")
        
        texts = response.text_annotations
        if texts:
            return texts[0].description
        return ""
    except Exception as e:
        app.logger.error(f"[OCR] è¾¨è­˜å¤±æ•—: {e}")
        raise

# ============================================
# OCR é…å°é‚è¼¯
# ============================================
def _pair_ids_with_numbers(text: str) -> Tuple[List[Tuple[str, str]], List[str]]:
    """é…å°å¯„æ›¸IDèˆ‡12ç¢¼å–®è™Ÿ"""
    lines = [ln.strip() for ln in text.split("\n") if ln.strip()]
    
    rid_pattern = re.compile(r"R\d{4}", re.IGNORECASE)
    num_pattern = re.compile(r"\d{12}")
    
    rids = []
    nums = []
    leftovers = []
    
    for line in lines:
        r_match = rid_pattern.search(line)
        n_match = num_pattern.search(line)
        
        if r_match:
            rids.append(r_match.group(0).upper())
        if n_match:
            nums.append(n_match.group(0))
        
        if not r_match and not n_match:
            leftovers.append(line)
    
    pairs = list(zip(rids, nums))
    return pairs, leftovers

def _write_ocr_results(pairs: List[Tuple[str, str]], event) -> str:
    """å¯«å…¥ OCR çµæœ"""
    try:
        uid = getattr(event.source, "user_id", "")
        profile = line_bot_api.get_profile(uid)
        operator = profile.display_name or "ç³»çµ±"
    except Exception:
        operator = "ç³»çµ±"
    
    try:
        ws = _ws(MAIN_SHEET_NAME)
        h = _get_header_map(ws)
        all_vals = ws.get_all_values()
        
        idx_rid = _col_idx(h, "å¯„æ›¸ID", 1)
        idx_tracking = _col_idx(h, "å·²è¨—é‹-12ç¢¼å–®è™Ÿ", 10)
        idx_date = _col_idx(h, "å·²è¨—é‹-å¯„å‡ºæ—¥æœŸ", 11)
        idx_person = _col_idx(h, "å·²è¨—é‹-ç¶“æ‰‹äºº", 12)
        idx_status = _col_idx(h, "ç‹€æ…‹", 13)
        
        success_count = 0
        not_found = []
        
        for rid, tracking_num in pairs:
            found_row = None
            for i, r in enumerate(all_vals[1:], start=2):
                if len(r) >= idx_rid and r[idx_rid - 1] == rid:
                    found_row = i
                    break
            
            if found_row:
                _safe_update_cell(ws, found_row, idx_tracking, tracking_num)
                _safe_update_cell(ws, found_row, idx_date, today_str())
                _safe_update_cell(ws, found_row, idx_person, operator)
                _safe_update_cell(ws, found_row, idx_status, "å·²è¨—é‹")
                success_count += 1
                app.logger.info(f"[OCR] æ›´æ–° {rid} -> {tracking_num}")
            else:
                not_found.append(rid)
        
        msg = f"âœ… å·²æ›´æ–° {success_count} ç­†å‡ºè²¨å–®"
        if not_found:
            msg += f"\n\nâš ï¸ æ‰¾ä¸åˆ°ä»¥ä¸‹ IDï¼š\n" + "\n".join(not_found)
        
        return msg
    except Exception as e:
        app.logger.error(f"[OCR] å¯«å…¥å¤±æ•—: {e}")
        raise

# ============================================
# å¯„æ›¸åŠŸèƒ½ï¼ˆå«é©—è­‰èˆ‡å¼•å°ä¿®æ­£ï¼‰
# ============================================
def _validate_order_data(data: Dict[str, str]) -> Dict[str, List[str]]:
    """é©—è­‰å¯„æ›¸è³‡æ–™ï¼Œåªå›å‚³çœŸæ­£æœ‰å•é¡Œçš„æ¬„ä½ï¼ˆæ–°åŠŸèƒ½ï¼‰"""
    errors = {
        "name": [],
        "phone": [],
        "address": [],
        "books": []
    }
    
    # é©—è­‰å§“åï¼šæœ‰å¡«å°±å¥½
    name = data.get("name", "").strip()
    if not name:
        errors["name"].append("å§“åç‚ºå¿…å¡«")
    
    # é©—è­‰é›»è©±ï¼š09 é–‹é ­ + 10 ä½æ•¸
    phone_raw = data.get("phone", "").strip()
    if not phone_raw:
        errors["phone"].append("é›»è©±ç‚ºå¿…å¡«")
    else:
        phone = normalize_phone(phone_raw)
        if not phone:
            errors["phone"].append(f"é›»è©±æ ¼å¼éŒ¯èª¤ï¼šã€Œ{phone_raw}ã€ï¼ˆéœ€ç‚º 09 é–‹é ­çš„ 10 ç¢¼æ‰‹æ©Ÿè™Ÿç¢¼ï¼‰")
    
    # é©—è­‰åœ°å€ï¼šéœ€æ‰¾åˆ°éƒµéå€è™Ÿ
    address = data.get("address", "").strip()
    if not address:
        errors["address"].append("åœ°å€ç‚ºå¿…å¡«")
    else:
        zip_code = _find_zip_code(address)
        if not zip_code:
            errors["address"].append(f"æ‰¾ä¸åˆ°éƒµéå€è™Ÿï¼šã€Œ{address}ã€ï¼ˆè«‹è£œå……å®Œæ•´åœ°å€å«å€åŸŸï¼Œä¾‹ï¼šå°å—å¸‚åŒ—å€ï¼‰")
    
    # é©—è­‰æ›¸ç±
    book_raw = data.get("book", "").strip()
    if not book_raw:
        errors["books"].append("æ›¸ç±åç¨±ç‚ºå¿…å¡«")
    else:
        book_names = [x.strip() for x in re.split(r"[,ï¼Œã€;ï¼›\n]+", book_raw) if x.strip()]
        invalid_books = []
        
        for book_name in book_names:
            matched = _find_book_exact(book_name)
            if not matched:
                invalid_books.append(book_name)
        
        if invalid_books:
            for wrong_name in invalid_books:
                suggestions = _suggest_books(wrong_name)
                if suggestions:
                    errors["books"].append({
                        "wrong": wrong_name,
                        "suggestions": suggestions
                    })
                else:
                    errors["books"].append({
                        "wrong": wrong_name,
                        "suggestions": []
                    })
    
    # ç§»é™¤ç©ºéŒ¯èª¤ï¼ˆåªå›å‚³çœŸæ­£æœ‰å•é¡Œçš„ï¼‰
    return {k: v for k, v in errors.items() if v}

def _format_validation_errors(errors: Dict[str, List]) -> str:
    """æ ¼å¼åŒ–é©—è­‰éŒ¯èª¤è¨Šæ¯ï¼ˆåªé¡¯ç¤ºçœŸæ­£æœ‰å•é¡Œçš„æ¬„ä½ï¼‰"""
    lines = ["âŒ ç™¼ç¾ä»¥ä¸‹å•é¡Œï¼š\n"]
    error_num = 1
    
    # å§“åéŒ¯èª¤
    if "name" in errors:
        for err in errors["name"]:
            lines.append(f"{error_num}. {err}")
            error_num += 1
    
    # é›»è©±éŒ¯èª¤
    if "phone" in errors:
        for err in errors["phone"]:
            lines.append(f"{error_num}. {err}")
            error_num += 1
    
    # åœ°å€éŒ¯èª¤
    if "address" in errors:
        for err in errors["address"]:
            lines.append(f"{error_num}. {err}")
            error_num += 1
    
    # æ›¸ç±éŒ¯èª¤
    if "books" in errors:
        for err_item in errors["books"]:
            if isinstance(err_item, dict):
                wrong = err_item["wrong"]
                suggestions = err_item["suggestions"]
                lines.append(f"{error_num}. æ›¸ç±åç¨±éŒ¯èª¤ï¼šã€Œ{wrong}ã€")
                if suggestions:
                    lines.append("   â†’ å»ºè­°æ›¸ç±ï¼š")
                    for i, sugg in enumerate(suggestions, start=1):
                        lines.append(f"     [{i}] {sugg}")
                else:
                    lines.append("   â†’ æ‰¾ä¸åˆ°ç›¸ä¼¼æ›¸ç±ï¼Œè«‹ä½¿ç”¨ã€Œ#æŸ¥æ›¸åã€ç¢ºèª")
                error_num += 1
            else:
                lines.append(f"{error_num}. {err_item}")
                error_num += 1
    
    lines.append("\n---")
    lines.append("ğŸ“ ä¿®æ­£æ–¹å¼ï¼š")
    
    # æ ¹æ“šéŒ¯èª¤é¡å‹çµ¦äºˆä¸åŒæç¤º
    if "books" in errors and any(isinstance(e, dict) and e.get("suggestions") for e in errors["books"]):
        lines.append("â€¢ æ›¸ç±è«‹å›è¦†æ•¸å­—é¸æ“‡ï¼ˆä¾‹ï¼š1ï¼‰")
    
    if "name" in errors or "phone" in errors or "address" in errors:
        lines.append("â€¢ è«‹é‡æ–°è¼¸å…¥å®Œæ•´ #å¯„æ›¸ è³‡æ–™ï¼ˆå«ä¿®æ­£é …ç›®ï¼‰")
    
    lines.append("â€¢ æˆ–å›è¦†ã€ŒNã€å–æ¶ˆæœ¬æ¬¡ç™»è¨˜")
    
    return "\n".join(lines)

def _handle_new_order(event, text: str):
    """è™•ç†æ–°å¯„æ›¸ï¼ˆå«é©—è­‰ï¼Œä¿®å¾© M2ï¼šçµ±ä¸€å‘½åï¼‰"""
    lines_after = text.replace("#å¯„æ›¸", "").strip()
    data = parse_kv_lines(lines_after)
    
    name = data.get("å§“å", "").strip()
    phone_raw = data.get("é›»è©±", "").strip()
    address_raw = data.get("å¯„é€åœ°å€", "").strip()
    book_raw = data.get("æ›¸ç±åç¨±", "").strip()
    biz_note = data.get("æ¥­å‹™å‚™è¨»", "").strip()
    
    # é©—è­‰è³‡æ–™
    validation_data = {
        "name": name,
        "phone": phone_raw,
        "address": address_raw,
        "book": book_raw
    }
    
    errors = _validate_order_data(validation_data)
    
    if errors:
        # æœ‰éŒ¯èª¤ï¼Œé€²å…¥å¼•å°æµç¨‹
        error_msg = _format_validation_errors(errors)
        
        # å„²å­˜å¾…ä¿®æ­£è³‡æ–™
        _PENDING[event.source.user_id] = {
            "type": "order_correction",
            "data": validation_data,
            "errors": errors,
            "biz_note": biz_note
        }
        
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=error_msg))
        return
    
    # ç„¡éŒ¯èª¤ï¼Œç›´æ¥å»ºç«‹è¨‚å–®
    _create_order_confirmed(event, name, phone_raw, address_raw, book_raw, biz_note)

def _create_order_confirmed(event, name: str, phone_raw: str, address_raw: str, book_raw: str, biz_note: str):
    """ç¢ºèªç„¡èª¤å¾Œå»ºç«‹è¨‚å–®ï¼ˆæ ¹æ“šå¯¦éš›è¡¨é ­å‹•æ…‹å¯«å…¥ï¼‰"""
    try:
        uid = getattr(event.source, "user_id", "")
        profile = line_bot_api.get_profile(uid)
        operator = profile.display_name or "ç³»çµ±"
    except Exception:
        operator = "ç³»çµ±"
    
    app.logger.info(f"[ORDER] é–‹å§‹å»ºç«‹è¨‚å–® - å§“å:{name}, é›»è©±:{phone_raw}, æ›¸ç±:{book_raw}")
    
    phone = normalize_phone(phone_raw)
    zip_code = _find_zip_code(address_raw)
    
    if WRITE_ZIP_TO_ADDRESS and zip_code:
        address = f"{zip_code} {address_raw}"
    else:
        address = address_raw
    
    app.logger.info(f"[ORDER] è™•ç†å¾Œ - é›»è©±:{phone}, éƒµéå€è™Ÿ:{zip_code}, åœ°å€:{address}")
    
    # è§£ææ›¸å
    book_names = [x.strip() for x in re.split(r"[,ï¼Œã€;ï¼›\n]+", book_raw) if x.strip()]
    final_books = []
    for book_name in book_names:
        matched = _find_book_exact(book_name)
        if matched:
            final_books.append(matched)
        else:
            final_books.append(book_name)
    
    app.logger.info(f"[ORDER] è§£ææ›¸åå®Œæˆ: {final_books}")
    
    try:
        app.logger.info(f"[ORDER] æº–å‚™å¯«å…¥å·¥ä½œè¡¨: {MAIN_SHEET_NAME}")
        ws = _ws(MAIN_SHEET_NAME)
        h = _get_header_map(ws)
        app.logger.info(f"[ORDER] è¡¨é ­å°æ‡‰: {h}")
        
        all_vals = ws.get_all_values()
        header = all_vals[0] if all_vals else []
        app.logger.info(f"[ORDER] å¯¦éš›è¡¨é ­: {header}")
        app.logger.info(f"[ORDER] ç›®å‰è³‡æ–™åˆ—æ•¸: {len(all_vals)}")
        
        # ç”Ÿæˆæ–° ID
        # æ”¯æ´å¤šç¨® ID æ¬„ä½åç¨±
        idx_rid = _col_idx(h, "å¯„æ›¸ID", _col_idx(h, "ç´€éŒ„ID", 1))
        existing_ids = [r[idx_rid - 1] for r in all_vals[1:] if len(r) >= idx_rid and r[idx_rid - 1].startswith("R")]
        max_num = 0
        for eid in existing_ids:
            m = re.match(r"R(\d+)", eid)
            if m:
                max_num = max(max_num, int(m.group(1)))
        new_rid = f"R{max_num + 1:04d}"
        
        app.logger.info(f"[ORDER] ç”Ÿæˆæ–°ID: {new_rid} (ç›®å‰æœ€å¤§ç·¨è™Ÿ: {max_num})")
        
        # æ ¹æ“šè¡¨é ­æ¬„ä½æ•¸é‡å»ºç«‹ç©ºç™½åˆ—
        num_cols = len(header)
        
        # å¯«å…¥å¤šåˆ—
        for book in final_books:
            # å»ºç«‹ç©ºç™½åˆ—ï¼ˆå¡«æ»¿æ‰€æœ‰æ¬„ä½ï¼‰
            row = [""] * num_cols
            
            # æ ¹æ“šè¡¨é ­åç¨±å¡«å…¥å°æ‡‰è³‡æ–™
            # ID æ¬„ä½
            if "å¯„æ›¸ID" in h:
                row[h["å¯„æ›¸ID"] - 1] = new_rid
            elif "ç´€éŒ„ID" in h:
                row[h["ç´€éŒ„ID"] - 1] = new_rid
            
            # å»ºå–®æ—¥æœŸï¼ˆä½¿ç”¨ yyyy-mm-dd hh:mm æ ¼å¼ï¼‰
            if "å»ºå–®æ—¥æœŸ" in h:
                row[h["å»ºå–®æ—¥æœŸ"] - 1] = now_str_min()  # ä½¿ç”¨å®Œæ•´æ™‚é–“æ ¼å¼
            elif "å»ºå–®æ™‚é–“" in h:
                row[h["å»ºå–®æ™‚é–“"] - 1] = now_str_min()
            
            # å»ºå–®äºº
            if "å»ºå–®äºº" in h:
                row[h["å»ºå–®äºº"] - 1] = operator
            
            # å§“å
            if "å­¸å“¡å§“å" in h:
                row[h["å­¸å“¡å§“å"] - 1] = name
            elif "å§“å" in h:
                row[h["å§“å"] - 1] = name
            
            # é›»è©±
            if "å­¸å“¡é›»è©±" in h:
                row[h["å­¸å“¡é›»è©±"] - 1] = phone
            elif "é›»è©±" in h:
                row[h["é›»è©±"] - 1] = phone
            
            # åœ°å€
            if "å¯„é€åœ°å€" in h:
                row[h["å¯„é€åœ°å€"] - 1] = address
            elif "åœ°å€" in h:
                row[h["åœ°å€"] - 1] = address
            
            # æ›¸ç±
            if "æ›¸ç±åç¨±" in h:
                row[h["æ›¸ç±åç¨±"] - 1] = book
            
            # æ¥­å‹™å‚™è¨»
            if "æ¥­å‹™å‚™è¨»" in h:
                row[h["æ¥­å‹™å‚™è¨»"] - 1] = biz_note
            
            # ç¶“æ‰‹äººï¼ˆå»ºå–®æ™‚ä¸å¡«ï¼Œå‡ºè²¨æ™‚æ‰å¡«ï¼‰
            if "ç¶“æ‰‹äºº" in h:
                row[h["ç¶“æ‰‹äºº"] - 1] = ""
            elif "å·²è¨—é‹-ç¶“æ‰‹äºº" in h:
                row[h["å·²è¨—é‹-ç¶“æ‰‹äºº"] - 1] = ""
            
            # ç‹€æ…‹
            if "å¯„é€ç‹€æ…‹" in h:
                row[h["å¯„é€ç‹€æ…‹"] - 1] = "å¾…è™•ç†"
            elif "ç‹€æ…‹" in h:
                row[h["ç‹€æ…‹"] - 1] = "å¾…è™•ç†"
            
            app.logger.info(f"[ORDER] æº–å‚™å¯«å…¥: {row[:5]}... (å…± {len(row)} æ¬„)")
            _safe_append_row(ws, row)
            app.logger.info(f"[ORDER] âœ… æˆåŠŸå»ºç«‹å¯„æ›¸ {new_rid}: {name} / {book}")
        
        msg_lines = ["âœ… å¯„æ›¸å»ºç«‹å®Œæˆ"]
        msg_lines.append(f"å»ºå–®æ—¥æœŸï¼š{now_str_min()}")
        msg_lines.append(f"å§“åï¼š{name}  |  é›»è©±ï¼š{phone}")
        msg_lines.append(f"åœ°å€ï¼š{address}")
        msg_lines.append(f"æ›¸ç±ï¼š{', '.join(final_books)}")
        msg_lines.append("ç‹€æ…‹ï¼šå¾…è™•ç†")
        
        msg = "\n".join(msg_lines)
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
        app.logger.info(f"[ORDER] è¨‚å–®å»ºç«‹å®Œæˆï¼Œå·²å›è¦†ä½¿ç”¨è€…")
    except Exception as e:
        app.logger.error(f"[ORDER] âŒ å»ºç«‹å¤±æ•—: {e}", exc_info=True)
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"âŒ å»ºç«‹å¤±æ•—: {e}"))
        raise

# ============================================
# æŸ¥è©¢å¯„æ›¸
# ============================================
def _handle_query(event, text: str):
    """æŸ¥è©¢å¯„æ›¸ï¼ˆä¿®å¾© M1ï¼šå„ªåŒ–æŸ¥è©¢ï¼‰"""
    query = text.replace("#æŸ¥è©¢å¯„æ›¸", "").replace("#æŸ¥å¯„æ›¸", "").strip()
    
    if not query:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="è«‹è¼¸å…¥æŸ¥è©¢é—œéµå­—ï¼ˆå§“åæˆ–é›»è©±å¾Œ9ç¢¼ï¼‰"))
        return
    
    try:
        ws = _ws(MAIN_SHEET_NAME)
        h = _get_header_map(ws)
        all_vals = ws.get_all_values()
        
        idx_rid = _col_idx(h, "å¯„æ›¸ID", 1)
        idx_name = _col_idx(h, "å§“å", 2)
        idx_phone = _col_idx(h, "é›»è©±", 3)
        idx_book = _col_idx(h, "æ›¸ç±åç¨±", 5)
        idx_status = _col_idx(h, "ç‹€æ…‹", 13)
        
        # æŸ¥è©¢é‚è¼¯
        query_digits = re.sub(r"\D", "", query)
        matches = []
        
        for i, r in enumerate(all_vals[1:], start=2):
            if len(r) < max(idx_rid, idx_name, idx_phone, idx_book, idx_status):
                continue
            
            name = r[idx_name - 1] if len(r) >= idx_name else ""
            phone = r[idx_phone - 1] if len(r) >= idx_phone else ""
            
            # å§“åæ¯”å°
            if query in name:
                matches.append((i, r))
                continue
            
            # é›»è©±å¾Œ9ç¢¼æ¯”å°
            if query_digits and len(query_digits) >= PHONE_SUFFIX_MATCH:
                phone_digits = re.sub(r"\D", "", phone)
                if phone_digits.endswith(query_digits[-PHONE_SUFFIX_MATCH:]):
                    matches.append((i, r))
                    continue
        
        if not matches:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"æŸ¥ç„¡è³‡æ–™ï¼š{query}"))
            return
        
        # åˆä½µåŒ ID
        grouped = {}
        for row_i, r in matches:
            rid = r[idx_rid - 1]
            if rid not in grouped:
                grouped[rid] = {
                    "name": r[idx_name - 1],
                    "phone": r[idx_phone - 1],
                    "status": r[idx_status - 1],
                    "books": []
                }
            grouped[rid]["books"].append(r[idx_book - 1])
        
        # æ ¼å¼åŒ–è¼¸å‡º
        lines = [f"æŸ¥è©¢çµæœï¼ˆå…± {len(grouped)} ç­†ï¼‰ï¼š\n"]
        for rid, info in list(grouped.items())[:10]:  # æœ€å¤š10ç­†
            books_str = "ã€".join(info["books"])
            lines.append(f"{rid}: {info['name']}")
            lines.append(f"  é›»è©±: {info['phone']}")
            lines.append(f"  æ›¸ç±: {books_str}")
            lines.append(f"  ç‹€æ…‹: {info['status']}\n")
        
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="\n".join(lines)))
    except Exception as e:
        app.logger.error(f"[QUERY] æŸ¥è©¢å¤±æ•—: {e}")
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"âŒ æŸ¥è©¢å¤±æ•—: {e}"))

# ============================================
# å–æ¶ˆ/åˆªé™¤å¯„æ›¸ï¼ˆä¿®å¾© M3ï¼‰
# ============================================
def _handle_cancel_request(event, text: str):
    """è™•ç†å–æ¶ˆå¯„æ›¸è«‹æ±‚"""
    rid = text.replace("#å–æ¶ˆå¯„æ›¸", "").replace("#åˆªé™¤å¯„æ›¸", "").strip()
    
    if not rid:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="è«‹è¼¸å…¥å¯„æ›¸IDï¼ˆä¾‹ï¼š#å–æ¶ˆå¯„æ›¸ R0001ï¼‰"))
        return
    
    try:
        uid = getattr(event.source, "user_id", "")
        profile = line_bot_api.get_profile(uid)
        operator = profile.display_name or "ç³»çµ±"
    except Exception:
        operator = "ç³»çµ±"
    
    try:
        ws = _ws(MAIN_SHEET_NAME)
        h = _get_header_map(ws)
        all_vals = ws.get_all_values()
        
        idx_rid = _col_idx(h, "å¯„æ›¸ID", 1)
        idx_name = _col_idx(h, "å§“å", 2)
        idx_book = _col_idx(h, "æ›¸ç±åç¨±", 5)
        idx_status = _col_idx(h, "ç‹€æ…‹", 13)
        
        matching_rows = []
        for i, r in enumerate(all_vals[1:], start=2):
            if len(r) >= idx_rid and r[idx_rid - 1] == rid:
                matching_rows.append((i, r))
        
        if not matching_rows:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"æ‰¾ä¸åˆ°å¯„æ›¸IDï¼š{rid}"))
            return
        
        # æª¢æŸ¥æ˜¯å¦å·²å»ºå–®
        for row_i, r in matching_rows:
            status = r[idx_status - 1] if len(r) >= idx_status else ""
            if status != "å¾…è™•ç†":
                line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"âŒ {rid} å·²é€²å…¥ã€Œ{status}ã€ç‹€æ…‹ï¼Œç„¡æ³•å–æ¶ˆ"))
                return
        
        # å„²å­˜å¾…ç¢ºèª
        stu_name = matching_rows[0][1][idx_name - 1]
        book_list = "ã€".join([r[idx_book - 1] for _, r in matching_rows])
        
        _PENDING[event.source.user_id] = {
            "type": "cancel_order",
            "sheet": MAIN_SHEET_NAME,
            "rid": rid,
            "stu": stu_name,
            "book_list": book_list,
            "rows": [row_i for row_i, _ in matching_rows],
            "operator": operator,
            "idx": {
                "H": _col_idx(h, "å‚™è¨»", 8),
                "L": _col_idx(h, "å·²è¨—é‹-ç¶“æ‰‹äºº", 12),
                "M": _col_idx(h, "ç‹€æ…‹", 13)
            }
        }
        
        msg = f"ç¢ºèªåˆªé™¤å¯„æ›¸ï¼Ÿ\n{rid}: {stu_name}\næ›¸ç±ï¼š{book_list}\n\nå›è¦†ã€ŒY / YES / OKã€ç¢ºèªï¼›æˆ–å›è¦†ã€ŒNã€å–æ¶ˆã€‚"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
    except Exception as e:
        app.logger.error(f"[CANCEL] è™•ç†å¤±æ•—: {e}")
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"âŒ è™•ç†å¤±æ•—: {e}"))

# ============================================
# åˆªé™¤/å–æ¶ˆå‡ºæ›¸
# ============================================
def _handle_delete_ship(event, text: str):
    """åˆªé™¤å‡ºæ›¸è¨˜éŒ„"""
    rid = text.replace("#åˆªé™¤å‡ºæ›¸", "").replace("#å–æ¶ˆå‡ºæ›¸", "").strip()
    
    if not rid:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="è«‹è¼¸å…¥å¯„æ›¸IDï¼ˆä¾‹ï¼š#åˆªé™¤å‡ºæ›¸ R0001ï¼‰"))
        return
    
    try:
        ws = _ws(MAIN_SHEET_NAME)
        h = _get_header_map(ws)
        all_vals = ws.get_all_values()
        
        idx_rid = _col_idx(h, "å¯„æ›¸ID", 1)
        idx_tracking = _col_idx(h, "å·²è¨—é‹-12ç¢¼å–®è™Ÿ", 10)
        idx_date = _col_idx(h, "å·²è¨—é‹-å¯„å‡ºæ—¥æœŸ", 11)
        idx_person = _col_idx(h, "å·²è¨—é‹-ç¶“æ‰‹äºº", 12)
        idx_status = _col_idx(h, "ç‹€æ…‹", 13)
        
        found = False
        for i, r in enumerate(all_vals[1:], start=2):
            if len(r) >= idx_rid and r[idx_rid - 1] == rid:
                _safe_update_cell(ws, i, idx_tracking, "")
                _safe_update_cell(ws, i, idx_date, "")
                _safe_update_cell(ws, i, idx_person, "")
                _safe_update_cell(ws, i, idx_status, "å¾…è™•ç†")
                found = True
        
        if found:
            app.logger.info(f"[DELETE_SHIP] å·²æ’¤éŠ·å‡ºæ›¸: {rid}")
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"âœ… å·²æ’¤éŠ· {rid} çš„å‡ºè²¨è¨˜éŒ„"))
        else:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"æ‰¾ä¸åˆ°å¯„æ›¸IDï¼š{rid}"))
    except Exception as e:
        app.logger.error(f"[DELETE_SHIP] å¤±æ•—: {e}")
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"âŒ è™•ç†å¤±æ•—: {e}"))

# ============================================
# å…¥åº«åŠŸèƒ½
# ============================================
def _ensure_stockin_sheet():
    """ç¢ºä¿å…¥åº«æ˜ç´°è¡¨å­˜åœ¨"""
    return _get_or_create_ws(STOCK_IN_SHEET_NAME, ["å…¥åº«æ—¥æœŸ", "ç¶“æ‰‹äºº", "æ›¸å", "æ•¸é‡", "ä¾†æº", "å‚™è¨»"])

def _handle_stockin(event, text: str):
    """è™•ç†å…¥åº«ï¼ˆä¿®å¾© M2ï¼‰"""
    try:
        uid = getattr(event.source, "user_id", "")
        profile = line_bot_api.get_profile(uid)
        operator = profile.display_name or "ç³»çµ±"
    except Exception:
        operator = "ç³»çµ±"
    
    lines_after = text.replace("#è²·æ›¸", "").replace("#å…¥åº«", "").strip()
    
    if not lines_after:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="è«‹è¼¸å…¥æ›¸åèˆ‡æ•¸é‡ï¼ˆä¾‹ï¼š#å…¥åº« é¦–çˆ¾å¤§å­¸1A 5ï¼‰"))
        return
    
    # è§£ææ›¸åèˆ‡æ•¸é‡
    items = []
    for line in lines_after.split("\n"):
        line = line.strip()
        if not line:
            continue
        
        parts = line.split()
        if len(parts) < 2:
            continue
        
        qty_str = parts[-1]
        book_candidate = " ".join(parts[:-1])
        
        try:
            qty = int(qty_str)
        except ValueError:
            continue
        
        matched = _find_book_exact(book_candidate)
        if matched:
            items.append({"name": matched, "qty": qty})
    
    if not items:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âŒ ç„¡æ³•è¾¨è­˜æ›¸åï¼Œè«‹ä½¿ç”¨ã€Œ#æŸ¥æ›¸åã€ç¢ºèªæ­£ç¢ºæ›¸å"))
        return
    
    # åˆä½µç›¸åŒæ›¸å
    merged = {}
    for it in items:
        merged[it["name"]] = merged.get(it["name"], 0) + int(it["qty"])
    items = [{"name": k, "qty": v} for k, v in merged.items()]
    
    has_negative = any(it["qty"] < 0 for it in items)
    
    # å„²å­˜å¾…ç¢ºèª
    _PENDING[event.source.user_id] = {
        "type": "stock_in_confirm",
        "operator": operator,
        "items": items
    }
    
    lines = [f"â€¢ {it['name']} Ã— {it['qty']}" for it in items]
    suffix = "\n\nâ€» å«è² æ•¸ï¼ˆè‡ªå‹•æ¨™ç¤ºä¾†æºï¼šç›¤é»èª¿æ•´ï¼‰" if has_negative else ""
    msg = "è«‹ç¢ºèªå…¥åº«é …ç›®ï¼š\n" + "\n".join(lines) + suffix + "\n\nå›è¦†ã€ŒOK / YES / Yã€ç¢ºèªï¼›æˆ–å›è¦†ã€ŒNã€å–æ¶ˆã€‚"
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))

def _write_stockin_rows(operator: str, items: list):
    """å¯«å…¥å…¥åº«è¨˜éŒ„"""
    ws = _ensure_stockin_sheet()
    rows = []
    for it in items:
        qty = int(it["qty"])
        source = "è³¼è²·" if qty >= 0 else "ç›¤é»èª¿æ•´"
        rows.append([today_str(), operator, it["name"], qty, source, ""])
    _safe_append_rows(ws, rows)

# ============================================
# æ–°åŠŸèƒ½ï¼š#æŸ¥æ›¸å
# ============================================
def _handle_search_books(event, text: str):
    """è™•ç†æŸ¥æ›¸åæŒ‡ä»¤ï¼ˆæ–°åŠŸèƒ½ï¼‰"""
    keyword = text.replace("#æŸ¥æ›¸å", "").strip()
    
    if not keyword:
        msg = (
            "ğŸ“š æŸ¥æ›¸åä½¿ç”¨èªªæ˜ï¼š\n\n"
            "è«‹è¼¸å…¥é—œéµå­—æœå°‹æ›¸ç±ï¼Œä¾‹å¦‚ï¼š\n"
            "â€¢ #æŸ¥æ›¸å éŸ“æ–‡\n"
            "â€¢ #æŸ¥æ›¸å é¦–çˆ¾\n"
            "â€¢ #æŸ¥æ›¸å startup\n"
            "â€¢ #æŸ¥æ›¸å å¤šç›Š\n"
            "â€¢ #æŸ¥æ›¸å å…’ç«¥\n\n"
            "ç³»çµ±æœƒåˆ—å‡ºæ‰€æœ‰ç¬¦åˆçš„æ›¸ç±åç¨±"
        )
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
        return
    
    results = _search_books_by_keyword(keyword)
    
    if not results:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"æ‰¾ä¸åˆ°åŒ…å«ã€Œ{keyword}ã€çš„æ›¸ç±"))
        return
    
    # ä¾èªåˆ¥åˆ†çµ„
    grouped = {}
    for book in results:
        lang = book["lang"] or "å…¶ä»–"
        if lang not in grouped:
            grouped[lang] = []
        grouped[lang].append(book)
    
    # æ ¼å¼åŒ–è¼¸å‡º
    lines = [f"æ‰¾åˆ° {len(results)} æœ¬æ›¸ç±ï¼š\n"]
    
    for lang, books in sorted(grouped.items()):
        lines.append(f"ã€{lang}ã€‘")
        for book in books[:20]:  # æ¯é¡æœ€å¤š20æœ¬
            stock_info = f"ï¼ˆåº«å­˜ {book['stock']}ï¼‰" if book['stock'] != "" else ""
            lines.append(f"  â€¢ {book['name']} {stock_info}")
        if len(books) > 20:
            lines.append(f"  ... é‚„æœ‰ {len(books) - 20} æœ¬")
        lines.append("")
    
    # LINE è¨Šæ¯é•·åº¦é™åˆ¶
    msg = "\n".join(lines)
    if len(msg) > 4500:
        msg = msg[:4500] + "\n\nâš ï¸ çµæœéå¤šï¼Œå·²æˆªæ–·ã€‚è«‹ä½¿ç”¨æ›´ç²¾ç¢ºçš„é—œéµå­—ã€‚"
    
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))

# ============================================
# æ•´ç†å¯„æ›¸ï¼ˆä¿ç•™åŸåŠŸèƒ½ï¼‰
# ============================================
def _handle_organize_order(event, text: str):
    """æ•´ç†å¯„æ›¸åŠŸèƒ½ï¼ˆä¿®å¾© M2ï¼šçµ±ä¸€å‘½åï¼‰"""
    lines_after = text.replace("#æ•´ç†å¯„æ›¸", "").strip()
    data = parse_kv_lines(lines_after)
    
    name = data.get("å§“å", "").strip()
    phone = data.get("é›»è©±", "").strip()
    address = data.get("å¯„é€åœ°å€", "").strip()
    book_raw = data.get("æ›¸ç±åç¨±", "").strip()
    biz_note = data.get("æ¥­å‹™å‚™è¨»", "").strip()
    
    if not all([name, phone, address, book_raw]):
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âŒ è³‡æ–™ä¸å®Œæ•´ï¼ˆéœ€ï¼šå§“åã€é›»è©±ã€åœ°å€ã€æ›¸ç±åç¨±ï¼‰"))
        return
    
    _PENDING[event.source.user_id] = {
        "type": "organize_order_confirm",
        "data": {
            "name": name,
            "phone": phone,
            "address": address,
            "book_raw": book_raw,
            "biz_note": biz_note
        }
    }
    
    msg = f"ç¢ºèªå»ºç«‹å¯„æ›¸ï¼Ÿ\nå§“åï¼š{name}\né›»è©±ï¼š{phone}\nåœ°å€ï¼š{address}\næ›¸ç±ï¼š{book_raw}\n\nå›è¦†ã€ŒY / YES / OKã€ç¢ºèªï¼›æˆ–å›è¦†ã€ŒNã€å–æ¶ˆã€‚"
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))

# ============================================
# è™•ç†å¾…ç¢ºèªå›ç­”ï¼ˆä¿®å¾© S2ï¼šç§»é™¤é‡è¤‡ç¨‹å¼ç¢¼ï¼‰
# ============================================
def _handle_pending_answer(event, text: str) -> bool:
    """è™•ç†å¾…ç¢ºèªå›ç­”"""
    pend = _PENDING.get(event.source.user_id)
    if not pend:
        return False
    
    ans = text.strip().upper()
    
    # å–æ¶ˆ
    if ans == "N":
        _PENDING.pop(event.source.user_id, None)
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="å·²å–æ¶ˆã€‚"))
        return True
    
    # è™•ç†æ›¸ç±é¸æ“‡ï¼ˆæ•¸å­—ï¼‰
    if pend.get("type") == "order_correction" and ans.isdigit():
        return _handle_book_selection(event, int(ans))
    
    # é‡æ–°è¼¸å…¥
    if ans in ("é‡æ–°è¼¸å…¥", "RETRY", "REDO"):
        _PENDING.pop(event.source.user_id, None)
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="å·²æ¸…é™¤ï¼Œè«‹é‡æ–°è¼¸å…¥å®Œæ•´ #å¯„æ›¸ è³‡æ–™"))
        return True
    
    # ç¢ºèª
    if ans not in ("Y", "YES", "OK"):
        return False
    
    # å–æ¶ˆå¯„æ›¸
    if pend["type"] == "cancel_order":
        ws = _ws(pend["sheet"])
        idxH = pend["idx"]["H"]
        idxL = pend["idx"]["L"]
        idxM = pend["idx"]["M"]
        
        append_note = f"[å·²åˆªé™¤ {now_str_min()}]"
        for row_i in pend["rows"]:
            try:
                curr_h = ws.cell(row_i, idxH).value or ""
            except Exception:
                curr_h = ""
            new_h = (curr_h + " " + append_note).strip() if curr_h else append_note
            _safe_update_cell(ws, row_i, idxH, new_h)
            _safe_update_cell(ws, row_i, idxL, pend["operator"])
            _safe_update_cell(ws, row_i, idxM, "å·²åˆªé™¤")
        
        msg = f"âœ… å·²åˆªé™¤æ•´ç­†å¯„æ›¸ï¼ˆ{pend['rid']}ï¼‰ï¼š{pend['stu']} çš„ {pend['book_list']}"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=msg))
        _PENDING.pop(event.source.user_id, None)
        return True
    
    # å…¥åº«ç¢ºèª
    if pend["type"] == "stock_in_confirm":
        _write_stockin_rows(pend["operator"], pend["items"])
        lines = [f"{it['name']} Ã— {it['qty']}" for it in pend["items"]]
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âœ… å…¥åº«å®Œæˆï¼š\n" + "\n".join(lines)))
        _PENDING.pop(event.source.user_id, None)
        return True
    
    # æ•´ç†å¯„æ›¸ç¢ºèªï¼ˆä¿®å¾© S2ï¼šåªä¿ç•™ä¸€ä»½ï¼‰
    if pend["type"] == "organize_order_confirm":
        data = pend["data"]
        fake_text = (
            "#å¯„æ›¸\n"
            f"å§“åï¼š{data['name']}\n"
            f"é›»è©±ï¼š{data['phone']}\n"
            f"å¯„é€åœ°å€ï¼š{data['address']}\n"
            f"æ›¸ç±åç¨±ï¼š{data['book_raw']}\n"
            f"æ¥­å‹™å‚™è¨»ï¼š{data['biz_note']}"
        )
        _handle_new_order(event, fake_text)
        _PENDING.pop(event.source.user_id, None)
        return True
    
    return False

def _handle_book_selection(event, choice: int) -> bool:
    """è™•ç†æ›¸ç±é¸æ“‡ï¼ˆæ–°åŠŸèƒ½ï¼‰"""
    pend = _PENDING.get(event.source.user_id)
    if not pend or pend.get("type") != "order_correction":
        return False
    
    errors = pend.get("errors", {})
    if "books" not in errors:
        return False
    
    # æ‰¾åˆ°ç¬¬ä¸€å€‹æœ‰å»ºè­°çš„éŒ¯èª¤æ›¸å
    for err_item in errors["books"]:
        if isinstance(err_item, dict) and err_item.get("suggestions"):
            suggestions = err_item["suggestions"]
            if 1 <= choice <= len(suggestions):
                selected_book = suggestions[choice - 1]
                
                # æ›´æ–°è³‡æ–™ä¸­çš„æ›¸å
                old_name = err_item["wrong"]
                current_books = pend["data"]["book"]
                new_books = current_books.replace(old_name, selected_book)
                pend["data"]["book"] = new_books
                
                # é‡æ–°é©—è­‰
                validation_data = pend["data"]
                new_errors = _validate_order_data(validation_data)
                
                if not new_errors:
                    # ç„¡éŒ¯èª¤ï¼Œç›´æ¥å»ºç«‹è¨‚å–®
                    _create_order_confirmed(
                        event,
                        validation_data["name"],
                        validation_data["phone"],
                        validation_data["address"],
                        new_books,
                        pend.get("biz_note", "")
                    )
                    _PENDING.pop(event.source.user_id, None)
                else:
                    # é‚„æœ‰å…¶ä»–éŒ¯èª¤ï¼Œç¹¼çºŒå¼•å°
                    pend["errors"] = new_errors
                    error_msg = _format_validation_errors(new_errors)
                    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=error_msg))
                
                return True
    
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âŒ ç„¡æ•ˆçš„é¸é …"))
    return True

# ============================================
# LINE Webhook
# ============================================
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature", "")
    body = request.get_data(as_text=True)
    app.logger.info("Request body: " + body)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return "OK"

@handler.add(MessageEvent, message=TextMessage)
def handle_text_message(event):
    """è™•ç†æ–‡å­—è¨Šæ¯"""
    text = (event.message.text or "").strip()
    
    # #æˆ‘çš„IDï¼ˆä¸å—ç™½åå–®é™åˆ¶ï¼‰
    if text.startswith("#æˆ‘çš„ID"):
        uid = getattr(event.source, "user_id", "")
        try:
            profile = line_bot_api.get_profile(uid)
            name = profile.display_name or "LINEä½¿ç”¨è€…"
        except Exception:
            name = "LINEä½¿ç”¨è€…"
        try:
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text=f"ä½ çš„ IDï¼š\n{uid}\né¡¯ç¤ºåç¨±ï¼š{name}\n\nè«‹æä¾›çµ¦ç®¡ç†å“¡åŠ å…¥ç™½åå–®ã€‚")
            )
        except Exception:
            pass
        if uid:
            _log_candidate(uid, name)
        return
    
    # å¾…ç¢ºèªæµç¨‹
    if _handle_pending_answer(event, text):
        return
    
    # ç™½åå–®æª¢æŸ¥
    if not _ensure_authorized(event, scope="text"):
        return
    
    # è™•ç†æŒ‡ä»¤
    if text.startswith("#æŸ¥æ›¸å"):
        _handle_search_books(event, text)
        return
    
    if text.startswith("#æ•´ç†å¯„æ›¸"):
        _handle_organize_order(event, text)
        return
    
    if text.startswith("#å¯„æ›¸"):
        _handle_new_order(event, text)
        return
    
    if text.startswith("#æŸ¥è©¢å¯„æ›¸") or text.startswith("#æŸ¥å¯„æ›¸"):
        _handle_query(event, text)
        return
    
    if text.startswith("#å–æ¶ˆå¯„æ›¸") or text.startswith("#åˆªé™¤å¯„æ›¸"):
        _handle_cancel_request(event, text)
        return
    
    if text.startswith("#åˆªé™¤å‡ºæ›¸") or text.startswith("#å–æ¶ˆå‡ºæ›¸"):
        _handle_delete_ship(event, text)
        return
    
    if text.startswith("#å‡ºæ›¸"):
        _start_ocr_session(getattr(event.source, "user_id", ""))
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"å·²å•Ÿç”¨å‡ºæ›¸OCRï¼ˆ{OCR_SESSION_TTL_MIN} åˆ†é˜ï¼‰ã€‚è«‹ä¸Šå‚³å‡ºè²¨å–®ç…§ç‰‡ã€‚"))
        return
    
    if text.startswith("#è²·æ›¸") or text.startswith("#å…¥åº«"):
        _handle_stockin(event, text)
        return
    
    # å…¶ä»–æ–‡å­—ä¸è™•ç†

@handler.add(MessageEvent, message=ImageMessage)
def handle_image_message(event):
    """è™•ç†åœ–ç‰‡è¨Šæ¯"""
    if not _ensure_authorized(event, scope="image"):
        return
    
    uid = getattr(event.source, "user_id", "")
    if not _has_ocr_session(uid):
        return
    
    try:
        app.logger.info(f"[IMG] æ”¶åˆ°åœ–ç‰‡ user_id={uid} msg_id={event.message.id}")
        img_bytes = _download_line_image_bytes(event.message.id)
        
        if not _vision_client:
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text="âŒ OCR éŒ¯èª¤ï¼šVision æœªåˆå§‹åŒ–ï¼ˆè«‹è¨­å®š GOOGLE_SERVICE_ACCOUNT_JSON_NEW ä¸¦å•Ÿç”¨ Vision APIï¼‰ã€‚")
            )
            return
        
        text = _ocr_text_from_bytes(img_bytes)
        if LOG_OCR_RAW:
            app.logger.info(f"[OCR_TEXT]\n{text}")
        
        pairs, leftovers = _pair_ids_with_numbers(text)
        resp = _write_ocr_results(pairs, event)
        
        if leftovers:
            resp += "\n\nâ—ä»¥ä¸‹é …ç›®éœ€äººå·¥æª¢æ ¸ï¼š\n" + "\n".join(leftovers[:MAX_LEFTOVER_ITEMS])
        
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=resp))
    except Exception as e:
        code = datetime.now(TZ).strftime("%Y%m%d%H%M%S")
        app.logger.exception("[OCR_ERROR]")
        try:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=f"âŒ OCR éŒ¯èª¤ï¼ˆä»£ç¢¼ {code}ï¼‰ï¼š{e}"))
        except Exception:
            pass
    finally:
        _clear_ocr_session(uid)

@app.route("/", methods=["GET"])
def index():
    """å¥åº·æª¢æŸ¥"""
    try:
        names = [ws.title for ws in ss.worksheets()]
        return "OK / Worksheets: " + ", ".join(names)
    except Exception as e:
        return f"OK / (Sheets not loaded) {e}"

if __name__ == "__main__":
    port = int(os.getenv("PORT", "8080"))
    app.run(host="0.0.0.0", port=port)
